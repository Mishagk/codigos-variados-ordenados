{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6801b3",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es el brindar ejemplos de acceso y uso de ambientes para simulación orientados al Reinforcement Learning (Aprendizaje por reforzamiento) mediante la libreria Gym. Link con documentacion: https://www.gymlibrary.dev/content/basic_usage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9bde74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:22:22.151832Z",
     "start_time": "2022-11-29T16:22:22.151832Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Librerias\n",
    "\n",
    "import gym\n",
    "import keyboard\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f0ec9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simulador GymAI > Ambientes diversos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf115f4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Escenario: LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f0426c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:07:27.333502Z",
     "start_time": "2022-11-28T03:07:23.407370Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: LunarLander-v2\n",
      "Acciones del espacio: Discrete(4)\n",
      "muestra ::  0\n",
      "muestra ::  3\n",
      "muestra ::  2\n",
      "muestra ::  1\n",
      "muestra ::  1\n",
      "muestra ::  3\n",
      "muestra ::  0\n",
      "muestra ::  2\n",
      "muestra ::  0\n",
      "muestra ::  0\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: -2.497033478022092 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: 0.3028158191380623 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -4.084324611699333 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.06415158466822277 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -4.230430849374488 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: 0.012746637376268383 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -2.8209334305346827 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: 0.44435753911477605 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.34957934879241637 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: 1.1449635758303611 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -2.2152398545693925 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: 1.199374137458393 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: 0.5782678686134091 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: -0.39931580881619655 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: -1.0205897198816831 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -2.729823545860671 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: 0.973169224956963 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.8272269772758125 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: -4.934150697483164 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 0.6306953972599001 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: 0.8484956601110138 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.10775034724173338 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.30228160250740643 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -3.8740962831673924 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -1.5181619457291322 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: -0.7609956752394851 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: -2.1027271739572755 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: -2.478108164921507 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.3946844182438827 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -1.5072828837337966 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -1.6521914239254443 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -3.1332412960061604 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -2.4452637053411364 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: -0.6616309017342974 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -1.8649748393497987 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: -3.095805060199693 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: -1.1563142141057756 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: -3.3463245673891877 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: -1.9385396426059913 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -3.505726530843218 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: -3.4463851406184163 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -2.7413437001413 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -1.8424036798431007 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: -1.8571298325692271 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: -1.5972672490282196 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: -2.317262857843957 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: -3.103316515477604 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: -2.1731876155705834 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: -2.05800974868298 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: -3.0253473947238545 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1 - de ambiente simulacion\n",
    "\n",
    "gym_env = \"LunarLander-v2\"\n",
    "env = gym.make(gym_env, render_mode=\"human\")\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "    \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7828ddd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Escenario: CartPole-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c8515c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:07:38.322030Z",
     "start_time": "2022-11-28T03:07:36.248554Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CartPole-v1\n",
      "Acciones del espacio: Discrete(2)\n",
      "muestra ::  0\n",
      "muestra ::  1\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "muestra ::  0\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "muestra ::  0\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: 1.0 ;term: True ;trun: False ;info: {}\n",
      "------- Finalizado (Consiguió objetivo) ---------------\n",
      "i: 11 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: 1.0 ;term: True ;trun: False ;info: {}\n",
      "------- Finalizado (Consiguió objetivo) ---------------\n",
      "i: 47 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 2 - de ambiente simulacion\n",
    "\n",
    "gym_env = \"CartPole-v1\"\n",
    "env = gym.make(gym_env, render_mode=\"human\")\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "\n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4639c9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Escenario: BipedalWalker-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdbf029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:07:48.152005Z",
     "start_time": "2022-11-28T03:07:46.115744Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: BipedalWalker-v3\n",
      "Acciones del espacio: Box(-1.0, 1.0, (4,), float32)\n",
      "muestra ::  [ 0.5479121  -0.12224312  0.71719587  0.39473605]\n",
      "muestra ::  [-0.8116453  0.9512447  0.5222794  0.5721286]\n",
      "muestra ::  [-0.74377275 -0.09922812 -0.25840396  0.85353   ]\n",
      "muestra ::  [ 0.28773025  0.64552325 -0.1131716  -0.5455226 ]\n",
      "muestra ::  [ 0.10916957 -0.8723655   0.65526235  0.2633288 ]\n",
      "muestra ::  [ 0.5161755  -0.29094806  0.94139606  0.78624225]\n",
      "muestra ::  [ 0.556767  -0.6107226 -0.066558  -0.9123925]\n",
      "muestra ::  [-0.69142103  0.3660979   0.4895243   0.9350195 ]\n",
      "muestra ::  [-0.34834927 -0.2590806  -0.06088838 -0.6210573 ]\n",
      "muestra ::  [-0.740157   -0.04859015 -0.5461813   0.33962798]\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: -0.03677048385639867 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: -0.12128347212386865 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -0.12639417488376062 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.18618398785591125 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -0.1334285677472762 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: -0.12666408969958506 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -0.17000708866119382 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: -0.024435176074504857 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.033851756831012554 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: 0.05692235102256376 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -0.09035675211747723 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: -0.046714869966108415 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: 0.05029917001289508 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: 0.06583368244767189 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: 0.03515792099634925 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -0.013376621777813822 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: -0.048433364883065225 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.008062145233154296 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: 0.03817116846392672 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 0.022094737824052572 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: 0.0020779402529188078 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.1674081994270273 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.14762182070811472 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -0.09895633501807967 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -0.006356225719053359 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: 0.06988523552566767 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: 0.045934727206826204 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: 0.042538841515779496 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.047774908423423766 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -0.026592801779508592 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -0.21871826105316716 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -0.11595947506030282 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -0.11892899042616405 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: -0.13629220004876336 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -0.056696600099403464 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: 0.009465642149247345 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: 0.032888669649761115 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: 0.08048467103640358 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: 0.002112373590469358 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -0.005413786649703978 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: 0.0285516682288908 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -0.0633392872015647 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -0.010249168938644346 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: 0.07046689116954803 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: 0.11549892012278003 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: 0.12938673095902042 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: 0.16951408779621124 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: 0.16054574155807494 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: 0.22392252137263494 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: 0.16408513531088828 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 3 - de ambiente simulacion\n",
    "\n",
    "gym_env = \"BipedalWalker-v3\"\n",
    "env = gym.make(gym_env, render_mode=\"human\")\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "\n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df69b124",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simulador GymAI > Box2D > Car Racing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478cc9e6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Caso de accion \"continua\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ece7103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:08:02.484932Z",
     "start_time": "2022-11-28T03:08:00.207194Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Acciones del espacio: Box([-1.  0.  0.], 1.0, (3,), float32)\n",
      "muestra ::  [0.5479121  0.43887845 0.85859793]\n",
      "muestra ::  [0.39473605 0.09417735 0.97562236]\n",
      "muestra ::  [0.5222794  0.7860643  0.12811363]\n",
      "muestra ::  [-0.09922812  0.37079802  0.92676497]\n",
      "muestra ::  [0.28773025 0.8227616  0.4434142 ]\n",
      "muestra ::  [-0.5455226   0.5545848   0.06381726]\n",
      "muestra ::  [0.65526235 0.6316644  0.75808775]\n",
      "muestra ::  [-0.29094806  0.970698    0.8931211 ]\n",
      "muestra ::  [0.556767   0.19463871 0.466721  ]\n",
      "muestra ::  [-0.9123925   0.1542895   0.68304896]\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: 6.967137809187279 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 3.4335689045936393 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 4 (opcion continua) - de ambiente simulacion de carros\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "gym_env = \"CarRacing-v2\"\n",
    "env = gym.make(gym_env, render_mode=\"human\",continuous=True,lap_complete_percent=1.00)\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "    \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c5e1a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Caso de accion \"discreta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2b8987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:08:11.094248Z",
     "start_time": "2022-11-28T03:08:08.763953Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Acciones del espacio: Discrete(5)\n",
      "muestra ::  0\n",
      "muestra ::  3\n",
      "muestra ::  3\n",
      "muestra ::  2\n",
      "muestra ::  2\n",
      "muestra ::  4\n",
      "muestra ::  0\n",
      "muestra ::  3\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: 6.967137809187279 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -0.10000000000000009 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -0.10000000000000009 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -0.10000000000000009 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: 3.4335689045936397 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 4 (opcion discreta) - de ambiente simulacion de carros\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "gym_env = \"CarRacing-v2\"\n",
    "env = gym.make(gym_env, render_mode=\"human\",continuous=False,lap_complete_percent=1.00)\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "    \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8e763f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:08:29.085499Z",
     "start_time": "2022-11-28T03:08:28.962160Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq4AAAKsCAYAAAAtNz8NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAinUlEQVR4nO3db6xtd1kn8O+v5957bltK/1DoYNsZQFAHGR1MA2iJQXASRon0BTBMHKcxEN44459IHPANmcTJaCIqMWjSgKaTkAFTUZjBOFGEDLyQcBESRsqMplpoc5GiLb0C9/z9zYuzDQXvWvecfffeaz/nfD7JTe9ez1lrPbdde53v/XXt57TeewAAYN1dNXUDAABwGIIrAAAlCK4AAJQguAIAUILgCgBACYIrAAAlnLqSnVtrL0/ytiQbSd7Re//Fsa8/e9PZft3t113JKTnO9kdquyvrgnW1N1J7dGVdUNHYd7obVtUEcFgXzl/IxccutkvV5g6urbWNJG9P8q+SPJTk46219/fePzO0z3W3X5e7/uCueU/JcffVkdpjq2qCtfXlkdp7VtYFFT1tpHbXqpoADuv3//3vD9au5FGBFyT5y977A7337STvTvLKKzgeAAAMupLgemuSzz/h9UOzbQAAsHBL/3BWa+0NrbVzrbVzF//24rJPBwDAMXUlwfXhJLc/4fVts23foPd+T+/9jt77HWefcvYKTgcAwEl2JcH140me01p7ZmvtTJLXJnn/YtoCAIBvNPdUgd77bmvtPyT5XzkYh/Vbvfc/X1hnnDzbUzfAOms7l5yMMisu9ly998UekGmdnroBYFGuaI5r7/0PkvzBgnoBAIBBfnIWAAAlCK4AAJQguAIAUILgCgBACYIrAAAlXNFUAViorakbYJ21/eGZVxunNlbYybBFj9Faxliude9xKaPINhd/SGAaVlwBAChBcAUAoATBFQCAEgRXAABKEFwBACjBVAFWa3ektreyLqhoe+oGLq+14ckH63C8k6pvDk8q2B29KQHrxoorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJRgHBarVWCkEWtqf+oGKOv01A0Ai2LFFQCAEgRXAABKEFwBAChBcAUAoATBFQCAEgRXAABKMA6L1dqaugHKcu0wp36qT90CsCBWXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKEFwBQCgBOOwWC0jjZiXiUbMy3c6ODasuAIAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACYaEsHg7I7X9lXXBMdO229QtUNXpqRsAFsWKKwAAJQiuAACUILgCAFCC4AoAQAmCKwAAJZgqwOJtTd0Ax9LecKn3PlhrzTSCE88SDRwb3s4AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUIJxWCze9tQNcBz17eGRV31/uLZKFUZvrUuPq+yjb67H9QFcOSuuAACUILgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCCcVgsnnFYLMPO1A1cXu/rP3apQo+L1k+N/JnHpnKdvH9VsPasuAIAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACcZhMb+hsVf7K+2Ck2Jv6gYo62lz1r56xO2J6xSWzIorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJRgHBbz25q6AU4U1xvz2pizdt0RtyfJxZHa2Bitseu7j9TghLHiCgBACYIrAAAlCK4AAJQguAIAUILgCgBACaYKMD+f8maVfLKaeZ1Z4bnOzlnbG6kNTSMYm1IwdjwozIorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJRgHBbjxkYQ7aysCzB+jfmtchzWvDZGatcdcXuSXBypPT5S2x2pwRqw4goAQAmCKwAAJQiuAACUILgCAFCC4AoAQAmCKwAAJRiHxbjtkdrYqCxYsL43csHNcS221uZvhlrGRk0dV2dHamPjsGDNWXEFAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBKMw2Lc1tQNwIG+tdhxWL2v/zy3kziyaxl/5n52/f9bL9zenDVYc1ZcAQAoQXAFAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAE47AYZxwW6+IEjvCpMLJr0eb+M49N0TqJSzTbI7WTd1lxjJzEtzMAAAUJrgAAlCC4AgBQguAKAEAJgisAACWYKkCyP1LbXVkXMM61yJix72anV9bF+jARhmPKiisAACUIrgAAlCC4AgBQguAKAEAJgisAACUIrgAAlGAcFsn2SK2vrAsYtzN1A6y1NmftuDIOi2PKiisAACUIrgAAlCC4AgBQguAKAEAJgisAACUIrgAAlHDZcVittduT/Lckt+RgONI9vfe3tdZuSvKeJM9I8tdJXtN7f3T0YLtJhr7impH9Ni/XJVfE2BTWxdj4NaPZGHMSv0/szVmDwg6z4rqb5Gd7789N8qIkP9Fae26SNyX5YO/9OUk+OHsNAABLcdng2ns/33v/s9nvLyS5P8mtSV6Z5N7Zl92b5K4l9QgAAEd7xrW19owkz0/ysSS39N7Pz0pfyMGjBAAAsBSHDq6ttScl+d0kP917f/yJtd57z8ATaK21N7TWzrXWzl189OIVNQsAwMl1qODaWjudg9D6rt77e2eb/6a19vRZ/elJvnipfXvv9/Te7+i933H2xrOL6BkAgBPossG1tdaSvDPJ/b33X3lC6f1J7p79/u4k71t8ewAAcOCy47CS3Jnkx5J8urX2qdm2n0/yi0l+p7X2uiQPJnnNZY+0n+RrA7Wh7WNdjo3QGquZXvuNjMNiXeyM1Iz3YczpqRuYgHs3J9Blg2vv/aNJ2kD5ZYttBwAALs3aIwAAJQiuAACUILgCAFCC4AoAQAmCKwAAJRxmHNb0dge2Pz6wPUkujNTGfg7CtSO1MyO1dTc2SsiYIdZE60MDTJKNUxsLPdfBD/xb3X6rOt66nW9ljMOCE8GKKwAAJQiuAACUILgCAFCC4AoAQAmCKwAAJdSYKjCPsQ/Ofm3O2tCnVq8Z2WesNvwB6sUb+/TpMf2QMQVtD5daW+wbZtHHO86WMYlgnmOO7jMyLWY/+0c+Vwkj7xc4rqy4AgBQguAKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJx3cc1jLsDGz/8sg+j4/Urh6pXTtSGxrLNcbYFCo4plOLqlvG6LBFH7OfHh6VVX4c1u7A9r2VdgGLN7R8OnJ7sOIKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJgisAACUYh7VswxNakq/OWTszsP2akX22RmqwJtr24scucUKcnbqBJXL/5rjaHNhuHBYAANUJrgAAlCC4AgBQguAKAEAJgisAACUIrgAAlGAcVkXbR9wOVexN3QBlbUzdwBIZh8VxNTQOa2RZ1YorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJRgHBawPnanboCyzk7dwBIZdchxdWZgexvexYorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlmCoArA+fnmZOfaNP3cKV2Rmp7a+sC1i8jZHaUAo1VQAAgOoEVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAASjAOC1gbfW94pNH+/nrMBGptZE7LmqjQ48JtTt3AFdqaugFYkgW/N624AgBQguAKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJxmEB62N7uNT78KisVVqXPtbFuoze6qeK/3cxDovjyjgsAABOIsEVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASjMMC1sf+1A1wVOsyHqzEOKyxFkdGwUFpZxZ7OCuuAACUILgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCCcVjA2mi7beoWqGrBI3eWYmekVmCaF4waSpQbiz2NFVcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEowVQBYHwv+9CknSIVrZ2vqBmCJNldzGiuuAACUILgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCCcVjAao3ddXZX1gXHzdVTN3AI21M3AEtkHBYAAHyd4AoAQAmCKwAAJQiuAACUILgCAFCC4AoAQAnGYQGrNXbX2VlZFxw3beoGZvpIzTgsjrMzqzmNFVcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKME4LGC1Lg6X9h/fHykuto3W1mV+0uId5z/boKunbmBmbOTV2KgsqOD0SG1FS6FWXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKEFwBQCgBOOwgPUxNkpowXo/vrOJKvzZFj6ya2Oxh5vb1tQNwBJtTt2AFVcAAIoQXAEAKEFwBQCgBMEVAIASBFcAAEowVQBYH/tTN8CqLHzywZnFHm5uK5yMASu3Bu8zK64AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUIJxWMD6MEqIea1yTM/YJK+dlXUBy9FGapsr62KQFVcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKOHQ47BaaxtJziV5uPf+itbaM5O8O8lTknwiyY/13g2zAea3P3UDlLXK4Y5bI7WxUVlQwemR2tiorBU5yorrTyW5/wmvfynJr/ben53k0SSvW2RjAADwRIcKrq2125L8cJJ3zF63JC9Nct/sS+5NctcS+gMAgCSHX3H9tSQ/l6//j7ynJHms9747e/1QklsX2xoAAHzdZYNra+0VSb7Ye//EPCdorb2htXautXbu4mMX5zkEAAAc6nH2O5P8SGvth5KcTfLkJG9LckNr7dRs1fW2JA9faufe+z1J7kmSp/7zp3psHQCAuVx2xbX3/ube+22992ckeW2SP+m9/2iSDyV51ezL7k7yvqV1CQDAiXclA0T+U5J3t9Z+Icknk7xzMS0BJ9bYmCEYs7nCcxn8yHG2yvfSHI4UXHvvH07y4dnvH0jygsW3BAAA/5ifnAUAQAmCKwAAJQiuAACUILgCAFCC4AoAQAlXMg4LYKGuGvu79Jx/ze59sT/3ZNHH4wjGroG2si6MbeN4OzN1A+OsuAIAUILgCgBACYIrAAAlCK4AAJQguAIAUIKpAsBKtT788e+NvjG840ipgnWfbrCMaQkL7/Hsiic67A9s311pF7B4Y1M4TBUAAIArJ7gCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCCcVjAao1NNDrGY4ZaG5s/M/3xShgZ07NzYWe4eM3IMcfGrG0PbF/xVC5YuLGRV2t+a7HiCgBACYIrAAAlCK4AAJQguAIAUILgCgBACYIrAAAlGIcFrNb+1A1Q1umR2oWR2t+P1DZHasZecVyNXfdrzoorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJRgHBawWltTN0BVfWPO+VRju12c75BQ2pmpG5ifFVcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKME4LGC19qdugLJOT90AFDK2NGkcFgAALJfgCgBACYIrAAAlCK4AAJQguAIAUIKpAsBKte02dQtU5TsWHF7hyQFjrLgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCC4AoAQAmGiwCrtTdc6r2vro8RrRnZtZY2pm4ACtmcuoHlsOIKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJgisAACUYhwWsVN8eHnm1v7+/wk7WQ4XRW+vSYz+zHuPSoIQzUzewHFZcAQAoQXAFAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAE47CA1dqbuoH10vv6j3iq0COcWENLkKdX2sXKWHEFAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBKMwwJWa3fqBqiqbxrLBf/I5tQNrJYVVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAASjBVAFitnakboKw2dQOwhs5M3cBqWXEFAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBJWOw7rdJKnDtS+MrLf1wa29ytrB5jA3tQNUNYJG/sDh7I5dQOrZcUVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEpY7TisloORWJdyw8h+Tx7Y/tWRfcZquyM1YLm2pm6Aslb7HQvWRxup7a+si7VgxRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAASqgxXGQoXj9pZJ+x2sWR2qMjtT5SAw5nZHRL7+v/JmttbC4NS1XjOxYs3tit8UsD24fGjybJtSO1q0dqa3D7s+IKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJgisAACWczOEiY3/q9Z/GA6X1rZE3WYH3n5FdExob7wN8o52R2mMjtcdHamOjsq4Z2L7g960VVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAAShBcAQAo4WSOw9qeugE4wfanbuD4qzCyay6WWmD5xu7RXxmpfXVg+9g4rKERWiM9uA0AAFCC4AoAQAmCKwAAJQiuAACUILgCAFDCyZwqsDV1A3CCmerBvDanbgAYNDTMZOyeP1TbHd7FiisAACUIrgAAlCC4AgBQguAKAEAJgisAACUIrgAAlHCo4Npau6G1dl9r7bOttftba9/bWruptfZHrbW/mP3zxmU3uzBbI7+A5dod+QVjrhr5BZwIh327vy3JH/bevyPJdye5P8mbknyw9/6cJB+cvQYAgKW4bHBtrV2f5PuTvDNJeu/bvffHkrwyyb2zL7s3yV3LaREAAA634vrMJI8k+e3W2idba+9orV2b5Jbe+/nZ13whyS3LahIAAA4TXE8l+Z4kv9l7f36Sr+SbHgvovfcM/LCv1tobWmvnWmvnLv7txSvtFwCAE+owwfWhJA/13j82e31fDoLs37TWnp4ks39+8VI7997v6b3f0Xu/4+xTzi6iZwAATqDLBtfe+xeSfL619u2zTS9L8pkk709y92zb3Unet5QOAQAgB48BHMZ/TPKu1tqZJA8k+fEchN7faa29LsmDSV6znBbnNDZaZ39lXQDfzNgr5rU5dQPA1A4VXHvvn0pyxyVKL1toNwAAMMDYZgAAShBcAQAoQXAFAKAEwRUAgBIEVwAASjjsOKx6tqZuALiknakboKw2dQPA1Ky4AgBQguAKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJxmEBq7U/dQOUtTl1A8DUrLgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFDC8Z0qsD11A8AlmfjBvDambgCYmhVXAABKEFwBAChBcAUAoATBFQCAEgRXAABKEFwBACih9jisnZHa/sq6AI7Ce5MxYyOvLLXAiec2AABACYIrAAAlCK4AAJQguAIAUILgCgBACYIrAAAl1B6HtT11A7BEZ0ZqfaS2O8c+q7Q1dQPLc/3jjw/Wrto/+hyw/auG1xa+/OQnH/l4JRiHBYxwGwAAoATBFQCAEgRXAABKEFwBAChBcAUAoATBFQCAEmqPwzrGY3Ug147Urh6p7Qxs/+rIPl8bqR19itO4RR9vxXZ3h+aNJf/iAx8YrD1rb+/I53pgY3g21Idf/erB2qlThW/tllOAEW4RAACUILgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFBC4ZkpSbanbgCuUBupbc55zNMD268f2efJI7WxUVljI7a+MrC9j+xTwKOPPjpYe9N11w3W/utNNx35XG/+u78brL1wpI+nPvWpRz7X2pj3ugdOBCuuAACUILgCAFCC4AoAQAmCKwAAJQiuAACUUGOqwM7A9v2VdgGLN/YOXOVfK8emG1wzZ+3MwPbiUwVOnx4a25DceOONg7XN7aOPQRk73lgfpVlOAUa4RQAAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACTXGYW1N3QAsyebUDSxR8bFXQ2644YbB2p133jlY2/jjPz7yue58yUuOvE95x/k9AVwxK64AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUIJxWDClM1M3sEQn8H173d///WDtW86fX+jxLjzpSUc+XgmWU4ARbhEAAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUEKNcVg7UzcAV6CN1DZX1sXq7U3dwOo9/1OfGqxtbh19PtjY8f73i1985OOVcHbqBoB1ZsUVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEpYn3FY2yO1/ZV1AYt3eqQ2NiqruotTN7B6O6fH/mNPf7wSNqZuAFhnVlwBAChBcAUAoATBFQCAEgRXAABKEFwBAChhfaYKbE3dACzJ5tQNTGRv6gaW40tf+tJg7a2f+9xg7bfa0UdIjB3v2771WwdrN99885HPtTbOTt0AsM6suAIAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACeszDmt76gZgSc5M3cBELk7dwHL03gdrz97dHax97ZprjnyuseON9VHa6akbANaZFVcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKGG147D67NelGIdFdW1g++ZKu1gfe1M3sBzXX3/9YO3bnvWswdojFy4c+VwvuO66wdr/G+mjNOOwgBFWXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKEFwBQCghNWPw9oZqUFlZ6ZuYM1sTd3Acpw5M/wf+q9f+MLh2qL7WPDx1sbZqRsA1pkVVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAAShBcAQAoYfXjsI7piBzI5tQNrJmh0XcwxnIKMMItAgCAEgRXAABKEFwBAChBcAUAoATBFQCAEkwVgEUxVeAb7U7dACV5HwEjrLgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCC4AoAQAmHGofVWvuZJK/PwUCrTyf58SRPT/LuJE9J8okkP9Z73x49UE+ycwXdwtTG/qp3emVd1HBx6gYoaWPqBoB1dtkV19barUl+Mskdvffn5eC28tokv5TkV3vvz07yaJLXLbNRAABOtsM+KnAqydWttVNJrklyPslLk9w3q9+b5K6FdwcAADOXDa6994eT/HKSz+UgsH45B48GPNZ7/4efjfNQklsvtX9r7Q2ttXOttXMXH/X/DgEAmM9hHhW4MckrkzwzybckuTbJyw97gt77Pb33O3rvd5y98ezcjQIAcLId5lGBH0zyV733R3rvO0nem+TOJDfMHh1IktuSPLykHgEA4FDB9XNJXtRau6a11pK8LMlnknwoyatmX3N3kvctp0UAADjEOKze+8daa/cl+bMku0k+meSeJB9I8u7W2i/Mtr3zsmfrs19Q1ZmpGyhkf+oGKOlQQxqBk+pQt4je+1uSvOWbNj+Q5AUL7wgAAC7BT84CAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAEg0fgKDanbqCQr03dACWdnroBYJ1ZcQUAoATBFQCAEgRXAABKEFwBAChBcAUAoATBFQCAEozDgqMwDuvw9qZugJI2pm4AWGdWXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKKH13ld3stZWdzIAAErqvbdLbbfiCgBACYIrAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACaembgAAWJ0nz7nf4wvtAuZjxRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAASlibcVg33XTTYO2WW2655Pb7779/cJ8XvvCFg7Vz584N1m6//fbB2s7OziW3nz9/fnCfs2fPDta2trYGa3t7e4M1AJjX1XPuZxwW68CKKwAAJQiuAACUILgCAFCC4AoAQAmCKwAAJQiuAACUsDbjsN7ylrcM1m688cZLbv+93/u9wX1e8pKXDNa+67u+a7D24he/eLA2NA7rPe95z+A+r371qwdrv/7rvz5Y+/SnPz1YAwA4iay4AgBQguAKAEAJgisAACUIrgAAlCC4AgBQwtpMFdjb2xusffzjH7/k9jvvvHNwn3vuuWew9vrXv36w9vDDDw/Wrr766ktuv+WWWwb3ufnmmwdr11577WANAIBvZMUVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEpYm3FYGxsbg7WnPe1pl9z+4IMPDu7znd/5nYO1Rx55ZLA2NtrqqqsunfPH+nj7298+WHve8543WPvTP/3TwRoAwElkxRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAASmi999WdrLXBk33f933f4H5DY6Pe9a53De7zxje+cbD2G7/xG4O1H/iBHxisXbhw4ZLbP/vZzw7uc/fddw/W3vrWtx75XABwJTbn3G9roV3AuN57u9R2K64AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUMLajMMCAIDEOCwAAIoTXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKOHU1A1wdG9+85uPvM9HPvKRwdpHP/rRkT1vHKn90JH7mNe1+SeDtZvynJX18eX8j8Ha4/nAyvoAgJPIiisAACUIrgAAlCC4AgBQguAKAEAJgisAACW03vvqTtba6k4GAEBJvfd2qe1WXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKOHUis/3pSQPzn5/8+w1XIrrgzGuD8a4Phjj+lh//2yo0Hrvq2zk6ydu7Vzv/Y5JTs7ac30wxvXBGNcHY1wftXlUAACAEgRXAABKmDK43jPhuVl/rg/GuD4Y4/pgjOujsMmecQUAgKPwqAAAACVMElxbay9vrf3f1tpfttbeNEUPrI/W2u2ttQ+11j7TWvvz1tpPzbbf1Fr7o9baX8z+eePUvTKN1tpGa+2TrbX/OXv9zNbax2b3kPe01s5M3SPTaK3d0Fq7r7X22dba/a2173Xv4B+01n5m9n3l/7TW/ntr7az7R20rD66ttY0kb0/yr5M8N8m/ba09d9V9sFZ2k/xs7/25SV6U5Cdm18Sbknyw9/6cJB+cveZk+qkk9z/h9S8l+dXe+7OTPJrkdZN0xTp4W5I/7L1/R5LvzsF14t5BWmu3JvnJJHf03p+XZCPJa+P+UdoUK64vSPKXvfcHeu/bSd6d5JUT9MGa6L2f773/2ez3F3LwjefWHFwX986+7N4kd03SIJNqrd2W5IeTvGP2uiV5aZL7Zl/i2jihWmvXJ/n+JO9Mkt77du/9sbh38HWnklzdWjuV5Jok5+P+UdoUwfXWJJ9/wuuHZtsgrbVnJHl+ko8luaX3fn5W+kKSW6bqi0n9WpKfS7I/e/2UJI/13ndnr91DTq5nJnkkyW/PHiV5R2vt2rh3kKT3/nCSX07yuRwE1i8n+UTcP0rz4SzWRmvtSUl+N8lP994ff2KtH4y/MALjhGmtvSLJF3vvn5i6F9bSqSTfk+Q3e+/PT/KVfNNjAe4dJ9fs2eZX5uAvON+S5NokL5+0Ka7YFMH14SS3P+H1bbNtnGCttdM5CK3v6r2/d7b5b1prT5/Vn57ki1P1x2TuTPIjrbW/zsFjRS/NwTONN8z+11/iHnKSPZTkod77x2av78tBkHXvIEl+MMlf9d4f6b3vJHlvDu4p7h+FTRFcP57kObNP9Z3JwYPS75+gD9bE7JnFdya5v/f+K08ovT/J3bPf353kfavujWn13t/ce7+t9/6MHNwr/qT3/qNJPpTkVbMvc22cUL33LyT5fGvt22ebXpbkM3Hv4MDnkryotXbN7PvMP1wf7h+FTfIDCFprP5SD59Y2kvxW7/2/rLwJ1kZr7cVJPpLk0/n6c4w/n4PnXH8nyT9N8mCS1/Te/26SJplca+0lSd7Ye39Fa+1ZOViBvSnJJ5P8u9771oTtMZHW2r/MwQf3ziR5IMmP52BRxr2DtNb+c5J/k4PpNZ9M8vocPNPq/lGUn5wFAEAJPpwFAEAJgisAACUIrgAAlCC4AgBQguAKAEAJgisAACUIrgAAlCC4AgBQwv8HxBtxuaLrjIsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ver un estado segun ambiente\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(observation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a266ca",
   "metadata": {
    "hidden": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3407be0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Simulacion de interaccion con teclado**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dcb281",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1) Simulador sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1772814d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T22:47:08.516093Z",
     "start_time": "2022-11-15T22:46:57.606946Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Simulador de Carro con ingreso por teclado\n",
    "\n",
    "import pygame\n",
    "from gym.utils.play import play\n",
    "\n",
    "# Mapeo de teclados - modo discreto\n",
    "mapping = {(pygame.K_SPACE,): 0,(pygame.K_RIGHT,): 1, (pygame.K_LEFT,): 2,(pygame.K_UP,): 3,(pygame.K_DOWN,): 4}\n",
    "\n",
    "# Simular con interaccion por teclado de computadora\n",
    "play(gym.make(\"CarRacing-v2\",render_mode=\"rgb_array_list\",continuous=False,lap_complete_percent=1.00), keys_to_action=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c766ba",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2) Simulacion por teclado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f0dc2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T04:48:00.353910Z",
     "start_time": "2022-11-16T04:47:49.630662Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Porcentaje a completar: 85.0 %\n",
      "Acciones del espacio: Discrete(5)\n",
      "-------------------------------------\n",
      "[INFO] Presione tecla para finalizar:  s\n",
      "[INICIO] Presione la tecla \"i\" para iniciar\n",
      "Se ha iniciado la simulacion\n",
      " *** Se presiono finalizar ***\n"
     ]
    }
   ],
   "source": [
    "# Simulador de Carro con ingreso por teclado\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "perc_complete = 0.85\n",
    "gym_env = \"CarRacing-v2\"\n",
    "\n",
    "env = gym.make(gym_env, render_mode=\"human\",\n",
    "               max_episode_steps=10000,\n",
    "               continuous=False,\n",
    "               lap_complete_percent=perc_complete)\n",
    "\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print('Porcentaje a completar:',np.round(100.*perc_complete,1),'%')\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "print('-------------------------------------')\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Tecla para finalizar\n",
    "tecla_finalizar = \"s\"\n",
    "print('[INFO] Presione tecla para finalizar: ',tecla_finalizar)\n",
    "\n",
    "# Informacion de teclados:\n",
    "## DERECHA: ir a la derecha (incluye girar)\n",
    "## IZQUIERDA: ir a la izquierda (incluye girar)\n",
    "## ARRIBA: avanzar aumentando velocidad\n",
    "## ABAJO: Reduce velocidad\n",
    "## TECLA SALIR definido arriba ver codigo lineas arriba\n",
    "\n",
    "# Parametro de finalizacion - en caso se equivoque mucho finalizar ya!!\n",
    "min_reward_to_finish = 12.5\n",
    "steps_batch = 300\n",
    "steps_to_finish = steps_batch\n",
    "reward_to_finish = 0\n",
    "finish_simulation = False\n",
    "\n",
    "#############################\n",
    "\n",
    "print('[INICIO] Presione la tecla \"i\" para iniciar')\n",
    "while(not keyboard.is_pressed(\"i\")):\n",
    "    pass\n",
    "\n",
    "print('Se ha iniciado la simulacion')\n",
    "observation, info = env.reset()\n",
    "\n",
    "#############################\n",
    "\n",
    "# Inicializar parametros\n",
    "time_start = time.time()\n",
    "reward_global = 0\n",
    "pasos_ciclo = 0\n",
    "num_ciclo = 1\n",
    "\n",
    "\n",
    "# Simulacion\n",
    "while True:\n",
    "    \n",
    "    # Accion por defecto en caso no se presione nada\n",
    "    accion = 0\n",
    "    \n",
    "    # En caso se presione alguna tecla en especifico\n",
    "    if keyboard.is_pressed(\"flecha derecha\"):\n",
    "        accion = 1\n",
    "    elif keyboard.is_pressed(\"flecha izquierda\"):\n",
    "        accion = 2\n",
    "    elif keyboard.is_pressed(\"flecha arriba\"):\n",
    "        accion = 3\n",
    "    elif keyboard.is_pressed(\"flecha abajo\"):\n",
    "        accion = 4\n",
    "    elif keyboard.is_pressed(tecla_finalizar):\n",
    "        print(' *** Se presiono finalizar ***')\n",
    "        break\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    # Leer estados del entorno\n",
    "    observation, reward, terminated, truncated, info = env.step(accion)\n",
    "    \n",
    "    reward_global += reward\n",
    "    pasos_ciclo += 1\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    #print('rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "        # Evaluar el reward ganado/perdido por cada intervalo. En caso no se evidencie mejora se finaliza\n",
    "    if(steps_to_finish < pasos_ciclo):\n",
    "        if(reward_global - reward_to_finish < min_reward_to_finish):\n",
    "            finish_simulation = True\n",
    "            \n",
    "        # Actualizar parametros\n",
    "        steps_to_finish += steps_batch\n",
    "        reward_to_finish = reward_global\n",
    "        \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated or finish_simulation:\n",
    "        \n",
    "        # Reset de entorno de simulacion\n",
    "        observation, info = env.reset()\n",
    "        \n",
    "        # tiempo de ciclo\n",
    "        duracion_ciclo = np.round(time.time() - time_start,1)\n",
    "        \n",
    "        # Informativo\n",
    "        print('# ciclo:',num_ciclo,'; completado:',terminated,'; truncado:',truncated,'; # pasos:',pasos_ciclo,'; reward:',np.round(reward_global,3),'; tiempo:',duracion_ciclo,'[sec] <> ',np.round(duracion_ciclo/60.0,2),'[min]')\n",
    "        \n",
    "        # Reiniciar/Actualizar variables\n",
    "        reward_global = 0\n",
    "        time_start = time.time()\n",
    "        pasos_ciclo = 0\n",
    "        num_ciclo += 1\n",
    "        \n",
    "        # Detener simulacion\n",
    "        steps_to_finish = steps_batch\n",
    "        reward_to_finish = 0\n",
    "        finish_simulation = False\n",
    "        \n",
    "        \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b460b66",
   "metadata": {
    "hidden": true
   },
   "source": [
    "3) Simulacion por teclado y generación de video para entrenamiento de Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3721a77e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T15:54:04.465583Z",
     "start_time": "2022-11-16T15:52:18.650013Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Porcentaje a completar: 85.0 %\n",
      "Acciones del espacio: Discrete(5)\n",
      "-------------------------------------\n",
      "[INFO] Presione tecla para finalizar:  s\n",
      "[INICIO] Presione la tecla \"i\" para iniciar\n",
      "Se ha iniciado la simulacion\n",
      "# ciclo: 1 ; completado: False ; truncado: False ; # pasos: 1379 ; reward: 842.428 ; tiempo: 29.2 [sec] <>  0.49 [min]\n",
      "# ciclo: 2 ; completado: False ; truncado: False ; # pasos: 530 ; reward: 337.572 ; tiempo: 11.8 [sec] <>  0.2 [min]\n",
      "# ciclo: 3 ; completado: False ; truncado: True ; # pasos: 955 ; reward: 904.5 ; tiempo: 19.5 [sec] <>  0.32 [min]\n",
      "# ciclo: 4 ; completado: False ; truncado: False ; # pasos: 463 ; reward: 323.953 ; tiempo: 10.5 [sec] <>  0.18 [min]\n",
      "# ciclo: 5 ; completado: False ; truncado: False ; # pasos: 578 ; reward: 508.302 ; tiempo: 12.8 [sec] <>  0.21 [min]\n",
      "# ciclo: 6 ; completado: False ; truncado: False ; # pasos: 870 ; reward: 735.785 ; tiempo: 18.8 [sec] <>  0.31 [min]\n",
      " *** Se presiono finalizar ***\n"
     ]
    }
   ],
   "source": [
    "# [Generar videos] Simulador de Carro con ingreso por teclado & grabar video\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "\n",
    "perc_complete = 0.85\n",
    "gym_env = \"CarRacing-v2\"\n",
    "\n",
    "env = gym.make(gym_env, render_mode=\"human\",\n",
    "               max_episode_steps=10000,\n",
    "               continuous=False,\n",
    "               lap_complete_percent=perc_complete)\n",
    "\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print('Porcentaje a completar:',np.round(100.*perc_complete,1),'%')\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "print('-------------------------------------')\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "#########################################\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Tecla para finalizar\n",
    "tecla_finalizar = \"s\"\n",
    "print('[INFO] Presione tecla para finalizar: ',tecla_finalizar)\n",
    "\n",
    "# Tecla para finalizar ciclo actual\n",
    "tecla_finaliza_ciclo = \"C\"\n",
    "\n",
    "# Informacion de teclados:\n",
    "## DERECHA: ir a la derecha (incluye girar)\n",
    "## IZQUIERDA: ir a la izquierda (incluye girar)\n",
    "## ARRIBA: avanzar aumentando velocidad\n",
    "## ABAJO: Reduce velocidad\n",
    "## TECLA SALIR: \"S\"      (Definido lineas arriba)\n",
    "## TECLA Finaliza ciclo actual: \"C\"   (Definido lineas arriba)\n",
    "\n",
    "# Parametro de finalizacion - en caso se equivoque mucho finalizar ya!!\n",
    "min_reward_to_finish = 12.5\n",
    "steps_batch = 300\n",
    "steps_to_finish = steps_batch\n",
    "reward_to_finish = 0\n",
    "finish_simulation = False\n",
    "\n",
    "#############################\n",
    "\n",
    "print('[INICIO] Presione la tecla \"i\" para iniciar')\n",
    "while(not keyboard.is_pressed(\"i\")):\n",
    "    pass\n",
    "\n",
    "print('Se ha iniciado la simulacion')\n",
    "observation, info = env.reset()\n",
    "\n",
    "#############################\n",
    "\n",
    "# Inicializar parametros\n",
    "time_start = time.time()\n",
    "reward_global = 0\n",
    "pasos_ciclo = 0\n",
    "num_ciclo = 1\n",
    "\n",
    "################################\n",
    "# Variable para guardar video\n",
    "num_simulacion = 1\n",
    "nombre_video = \"simula_\"+ str(num_simulacion) + \"_\" + str(num_ciclo) +\".mp4\"\n",
    "frame_size = env.observation_space.shape[:2]\n",
    "fps = 60\n",
    "\n",
    "# Inicio grabacion video\n",
    "result_video = cv2.VideoWriter(nombre_video, cv2.VideoWriter_fourcc(*'MP4V'),fps, frame_size)\n",
    "#################################\n",
    "\n",
    "# Simulacion\n",
    "while True:\n",
    "    \n",
    "    # Accion por defecto en caso no se presione nada\n",
    "    accion = 0\n",
    "    \n",
    "    # En caso se presione alguna tecla en especifico\n",
    "    if keyboard.is_pressed(\"flecha derecha\"):\n",
    "        accion = 1\n",
    "    elif keyboard.is_pressed(\"flecha izquierda\"):\n",
    "        accion = 2\n",
    "    elif keyboard.is_pressed(\"flecha arriba\"):\n",
    "        accion = 3\n",
    "    elif keyboard.is_pressed(\"flecha abajo\"):\n",
    "        accion = 4\n",
    "    elif keyboard.is_pressed(tecla_finaliza_ciclo):\n",
    "        finish_simulation = True\n",
    "        time.sleep(1) # esperar 1 segundo\n",
    "    elif keyboard.is_pressed(tecla_finalizar):\n",
    "        print(' *** Se presiono finalizar ***')\n",
    "        try:\n",
    "            # finaliza video\n",
    "            result_video.release()\n",
    "        except:\n",
    "            pass\n",
    "        # finalizar bucle while\n",
    "        break\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    # Leer estados del entorno\n",
    "    observation, reward, terminated, truncated, info = env.step(accion)\n",
    "    \n",
    "    reward_global += reward\n",
    "    pasos_ciclo += 1\n",
    "    \n",
    "    # Guadar imagen a video\n",
    "    result_video.write(observation[:,:,::-1])\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    #print('rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "        # Evaluar el reward ganado/perdido por cada intervalo. En caso no se evidencie mejora se finaliza\n",
    "    if(steps_to_finish < pasos_ciclo):\n",
    "        if(reward_global - reward_to_finish < min_reward_to_finish):\n",
    "            finish_simulation = True\n",
    "            \n",
    "        # Actualizar parametros\n",
    "        steps_to_finish += steps_batch\n",
    "        reward_to_finish = reward_global\n",
    "        \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated or finish_simulation:\n",
    "        \n",
    "        # Reset de entorno de simulacion\n",
    "        observation, info = env.reset()\n",
    "        \n",
    "        # tiempo de ciclo\n",
    "        duracion_ciclo = np.round(time.time() - time_start,1)\n",
    "        \n",
    "        # Informativo\n",
    "        print('# ciclo:',num_ciclo,'; completado:',terminated,'; truncado:',truncated,'; # pasos:',pasos_ciclo,'; reward:',np.round(reward_global,3),'; tiempo:',duracion_ciclo,'[sec] <> ',np.round(duracion_ciclo/60.0,2),'[min]')\n",
    "        \n",
    "        # Finaliza video\n",
    "        result_video.release()\n",
    "\n",
    "        # Reiniciar/Actualizar variables\n",
    "        reward_global = 0\n",
    "        time_start = time.time()\n",
    "        pasos_ciclo = 0\n",
    "        num_ciclo += 1\n",
    "        \n",
    "        # Detener simulacion\n",
    "        steps_to_finish = steps_batch\n",
    "        reward_to_finish = 0\n",
    "        finish_simulation = False\n",
    "        \n",
    "        # Inicializar video - empieza a grabar nuevo archivo\n",
    "        nombre_video = \"simula_\"+ str(num_simulacion) + \"_\" + str(num_ciclo) +\".mp4\"\n",
    "        result_video = cv2.VideoWriter(nombre_video, cv2.VideoWriter_fourcc(*'MP4V'),fps, frame_size)\n",
    "        \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de37c927",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Reinforcement Learning - Aplicación Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d4cc9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Aplicacion del algoritmo de Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8f46d5",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Frozen Lake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2578f50",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Aplicacion en el entorno frozen lake: https://www.gymlibrary.dev/environments/toy_text/frozen_lake/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c123a692",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Caso de tablero 4x4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4a9a92f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:29:47.570032Z",
     "start_time": "2022-11-29T16:29:39.829503Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exito en episodio: 29920 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29921 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29922 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29923 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29924 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29925 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29926 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29927 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29928 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29929 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29930 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29931 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29932 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29933 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29934 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29935 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29936 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29937 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29938 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29939 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29940 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29941 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29942 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29943 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29944 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29945 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29946 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29947 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29948 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29949 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29950 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29951 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29952 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29953 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29954 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29955 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29956 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29957 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29958 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29959 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29960 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29961 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29962 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29963 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29964 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29965 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29966 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29967 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29968 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29969 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29970 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29971 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29972 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29973 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29974 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29975 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29976 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29977 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29978 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29979 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29980 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29981 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29982 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29983 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29984 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29985 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29986 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29987 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29988 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29989 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29990 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29991 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29992 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29993 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29994 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29995 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29996 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29997 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29998 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "Exito en episodio: 29999 ; pasos: 5 ; estado: 15 ; reward: 501.0\n",
      "\n",
      "===========================================\n",
      "Q-Tabla final:\n",
      "[[ 2.66251894e+02  2.95835449e+02  2.95835449e+02  2.66251894e+02]\n",
      " [ 2.66236992e+02 -1.00000000e-05  3.28706066e+02  2.95661604e+02]\n",
      " [ 2.90393160e+02  3.65228973e+02  2.91501921e+02  3.28579638e+02]\n",
      " [ 3.28064061e+02 -9.99998093e-06  2.42677512e+02  7.39588448e+01]\n",
      " [ 2.95835449e+02  3.28706066e+02 -1.00000000e-05  2.66251894e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-9.99999523e-06  4.05809981e+02 -9.99998093e-06  3.28704202e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 3.28706066e+02 -1.00000000e-05  3.65228973e+02  2.95835449e+02]\n",
      " [ 3.28706066e+02  4.05809981e+02  4.05809981e+02 -1.00000000e-05]\n",
      " [ 3.65228973e+02  4.50899990e+02 -1.00000000e-05  3.65228973e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-9.99755859e-06  4.05589733e+02  4.50899990e+02  3.64872299e+02]\n",
      " [ 4.05809981e+02  4.50899990e+02  5.01000000e+02  4.05809981e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "Cantidad exito: 29520  de  30000 ; Ratio de exito= 98.4 %\n"
     ]
    }
   ],
   "source": [
    "# Caso 1 - Tabla 4x4\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "gym_env = \"FrozenLake-v1\"\n",
    "environment = gym.make(gym_env, is_slippery=False,map_name=\"4x4\")\n",
    "environment.reset()\n",
    "\n",
    "nb_states = environment.observation_space.n\n",
    "nb_actions = environment.action_space.n \n",
    "qtable = np.zeros((nb_states, nb_actions))\n",
    "\n",
    "# Artificio de agregar un valor diferente de cero inicial\n",
    "qtable = qtable + 0.0  \n",
    "\n",
    "\n",
    "# Hiperparametros\n",
    "episodes = 30000        # numero episodios\n",
    "alpha = 0.5            # Learning rate\n",
    "gamma = 0.9            # Discount factor\n",
    "epsilon = 0.90         # Amount of randomness in the action selection\n",
    "epsilon_decay = 0.001  # Fixed amount to decrease\n",
    "max_ii = 50            # limite de pasos por episodio\n",
    "\n",
    "print('Q-Tabla inicial:')\n",
    "print(qtable)\n",
    "\n",
    "# Llevar conteo de casos de exito\n",
    "cantidad_exitos = 0\n",
    "\n",
    "# guardar casos de exito\n",
    "camino_exitoso = []\n",
    "\n",
    "# Entrenamiento\n",
    "for ii in range(episodes):\n",
    "    \n",
    "    # Borrar salida\n",
    "    if(ii % 80 == 0):\n",
    "        clear_output()\n",
    "        \n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # camino seguido en episodio \n",
    "    camino_episodio_actual = []\n",
    "    \n",
    "    # tabla previa\n",
    "    qtable_anterior = qtable.copy()\n",
    "    \n",
    "    # flag para indicar si tuvo o no exito en episodio actual\n",
    "    exito_actual = 0\n",
    "    \n",
    "    # entrenar y actualizar matriz Q\n",
    "    while not done:\n",
    "        \n",
    "        # valor aleatorio entre 0 y 1\n",
    "        rnd = np.random.random()\n",
    "\n",
    "        # si se cumple rnd < epsilon tomar una accion aleatoria\n",
    "        if rnd < epsilon:\n",
    "            action = environment.action_space.sample()\n",
    "            \n",
    "        # si no es aleatorio, seleccionar la opcion con Q mas alto\n",
    "        else:\n",
    "            vector = qtable[state]\n",
    "            action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "             \n",
    "        # aplicar accion\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        # guardar camino\n",
    "        camino_episodio_actual.append((state,action,new_state))\n",
    "        \n",
    "        ################\n",
    "        \n",
    "        # Valor de recompensa en caso de lograr exitosamente descubrir el objetivo\n",
    "        reward_exito = 1\n",
    "        \n",
    "        # En caso de no llegar a recomensa y seguir en camino de aprendizaje penalizar cada paso\n",
    "        if reward < reward_exito:\n",
    "            reward = reward - 1e-5\n",
    "        \n",
    "        # En caso que se tenga exito en descubrir el objetivo - brindar una recompensa adicional mayor\n",
    "        if reward >= reward_exito:\n",
    "            reward = reward + 500\n",
    "        \n",
    "        ####################\n",
    "        \n",
    "        # Actualiza el valor de Q(s,a) segun accion y estado\n",
    "        qtable[state, action] = qtable[state, action] + \\\n",
    "                                alpha * (reward + gamma * np.max(qtable[new_state]) - qtable[state, action])\n",
    "        \n",
    "        # actualiza estado actual\n",
    "        state = new_state\n",
    "        \n",
    "        ###################\n",
    "        ## Exito conseguido\n",
    "        \n",
    "        if reward >= reward_exito:\n",
    "            \n",
    "            # Guardar camino exitoso\n",
    "            camino_exitoso.append(camino_episodio_actual)\n",
    "            \n",
    "            # Indicar que se tuvo exito\n",
    "            exito_actual = 1\n",
    "            \n",
    "            # Informativo\n",
    "            print('Exito en episodio:',ii,'; pasos:',pasos_ii,'; estado:',state,'; reward:',reward)\n",
    "        \n",
    "        ##################\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        \n",
    "        # En caso se exceda de la cantidad maximas de pasos en un episodio salir de bucle\n",
    "        if(pasos_ii > max_ii):\n",
    "            qtable = qtable_anterior.copy()\n",
    "            break\n",
    "    \n",
    "    ########################\n",
    "    #### fin episodio  #####\n",
    "    \n",
    "    # Contador de exitos\n",
    "    cantidad_exitos += exito_actual\n",
    "    \n",
    "    # Actualizar epsilon\n",
    "    epsilon = max(epsilon - epsilon_decay, 0)\n",
    "    \n",
    "    # Actualizar valor de tabla anterior\n",
    "    qtable_anterior = qtable.copy()\n",
    "\n",
    "print()\n",
    "print('===========================================')\n",
    "print('Q-Tabla final:')\n",
    "print(qtable)\n",
    "\n",
    "print (\"Cantidad exito:\",cantidad_exitos,\" de \",episodes,\"; Ratio de exito=\",np.round(100.*(cantidad_exitos/episodes),3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6b9f1ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:39:28.623110Z",
     "start_time": "2022-11-29T16:39:28.608107Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29520"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de caminos exitosos\n",
    "len(camino_exitoso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6f06f373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:39:29.243000Z",
     "start_time": "2022-11-29T16:39:29.226870Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tupla se lee: (state_actual, action, new_state)\n",
      "Indice i: -1  ; cantidad pasos: 6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1, 4), (4, 1, 8), (8, 2, 9), (9, 2, 10), (10, 1, 14), (14, 2, 15)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver cada camino seguido\n",
    "\n",
    "# cada tupla se lee: (state_actual, action, new_state)\n",
    "i = -1\n",
    "\n",
    "print('La tupla se lee: (state_actual, action, new_state)')\n",
    "print('Indice i:',i,' ; cantidad pasos:',len(camino_exitoso[i]))\n",
    "camino_exitoso[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cc3d2e5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:41:17.002798Z",
     "start_time": "2022-11-29T16:41:07.481790Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de animaciones a realizar: 5\n",
      "** ÉXITO ** Episode: 0 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "** ÉXITO ** Episode: 1 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "** ÉXITO ** Episode: 2 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "** ÉXITO ** Episode: 3 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "** ÉXITO ** Episode: 4 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Casos exito: 5 ; Ratio de exito= 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# [Ver animacion] Aplicar a \"Q\" entrenado\n",
    "\n",
    "environment = gym.make(gym_env, is_slippery=False,map_name=\"4x4\",render_mode=\"human\")\n",
    "environment.reset()\n",
    "\n",
    "# Cantidad de simulaciones\n",
    "episodes = 5\n",
    "print('Cantidad de animaciones a realizar:',episodes)\n",
    "\n",
    "# Registro de simulaciones exitosas\n",
    "nb_success = 0\n",
    "\n",
    " # limite de pasos por episodio\n",
    "max_ii = 100\n",
    "\n",
    "environment.render()\n",
    "\n",
    "# Evaluacion\n",
    "for ii in range(episodes):\n",
    "\n",
    "    # Inicializar entorno\n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # Hasta que finalice o se atore\n",
    "    while not done:\n",
    "        \n",
    "        # Seleccionar accion\n",
    "        vector = qtable[state]\n",
    "        action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "\n",
    "        # Aplicar accion y ver nuevos estados\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        #print('Estado:',new_state,'; Recompensa:',reward,'; Finalizacion:',done)\n",
    "        \n",
    "        # Actualizar estado\n",
    "        state = new_state\n",
    "        \n",
    "        # information\n",
    "        #print('Episode:',ii,'; num pasos:',pasos_ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "        \n",
    "        # Si se da recomensa, se ganó el juego\n",
    "        if reward >= reward_exito:\n",
    "            nb_success += 1\n",
    "            print('** ÉXITO **','Episode:',ii,'; num pasos:',pasos_ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "            break\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        if(pasos_ii > max_ii):\n",
    "            break\n",
    "\n",
    "print (\"Casos exito:\",nb_success,\"; Ratio de exito=\",np.round(100.*(nb_success/episodes),1),\"%\")\n",
    "environment.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c67fd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Caso de tablero 8x8**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1e9ff0f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:41:47.832474Z",
     "start_time": "2022-11-29T16:41:20.635231Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exito en episodio: 49920 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49921 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49922 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49923 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49924 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49925 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49926 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49927 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49928 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49929 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49930 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49931 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49932 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49933 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49934 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49935 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49936 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49937 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49938 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49939 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49940 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49941 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49942 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49943 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49944 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49945 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49946 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49947 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49948 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49949 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49950 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49951 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49952 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49953 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49954 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49955 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49956 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49957 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49958 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49959 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49960 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49961 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49962 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49963 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49964 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49965 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49966 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49967 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49968 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49969 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49970 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49971 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49972 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49973 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49974 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49975 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49976 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49977 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49978 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49979 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49980 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49981 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49982 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49983 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49984 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49985 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49986 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49987 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49988 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49989 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49990 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49991 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49992 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49993 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49994 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49995 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49996 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49997 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49998 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "Exito en episodio: 49999 ; pasos: 13 ; estado: 63 ; reward: 501.0\n",
      "\n",
      "===========================================\n",
      "Q-Tabla final:\n",
      "[[-2.68746805e-05 -2.68700375e-05  2.57184280e+02 -2.68747424e-05]\n",
      " [-2.03366849e-05  2.70720310e+02 -2.03372082e-05 -2.03402307e-05]\n",
      " [-1.45473878e-05 -1.21686879e-05 -1.45403865e-05 -1.45443518e-05]\n",
      " [-9.53071870e-06 -7.76519946e-06 -9.52674501e-06 -9.52591535e-06]\n",
      " [-5.84516505e-06 -4.49944632e-06 -5.83987009e-06 -5.84305720e-06]\n",
      " [-3.39263651e-06 -1.55250634e-06 -3.39353981e-06 -3.39099968e-06]\n",
      " [-2.00162394e-06 -1.68453198e-06 -2.00093671e-06 -1.99998325e-06]\n",
      " [-1.38321922e-06 -1.09324969e-06 -1.37525590e-06 -1.37528420e-06]\n",
      " [-2.04928692e-05 -2.04900799e-05 -1.85505319e-05 -2.04954773e-05]\n",
      " [-1.63038646e-05 -1.62933897e-05  2.84968759e+02 -1.62944614e-05]\n",
      " [-1.14975249e-05 -1.14874368e-05  2.99967126e+02 -1.14989672e-05]\n",
      " [-6.57977497e-06 -6.56831897e-06  3.15754880e+02 -6.57851351e-06]\n",
      " [-3.98108087e-06 -3.97737954e-06  3.32373569e+02 -3.97830372e-06]\n",
      " [-2.31159842e-06  3.49866925e+02 -2.30471941e-06 -2.31140180e-06]\n",
      " [-1.35198142e-06  5.73618754e-05 -1.34946853e-06 -1.35700989e-06]\n",
      " [-9.33798975e-07  7.78823964e-05 -9.27864241e-07 -9.36435048e-07]\n",
      " [-1.52753960e-05 -1.52766238e-05 -1.52721663e-05 -1.52808648e-05]\n",
      " [-1.23887464e-05 -1.23771247e-05 -1.23783938e-05 -1.23850485e-05]\n",
      " [-7.72609557e-06 -7.72366474e-06 -7.72075192e-06 -7.46263864e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.43651236e-06 -1.43480112e-06  5.59560843e-04 -1.43332029e-06]\n",
      " [-9.93170503e-07 -9.88215963e-07  3.68280984e+02 -9.90269907e-07]\n",
      " [-6.50108740e-07 -6.48574789e-07  3.87664204e+02 -6.51215427e-07]\n",
      " [-4.79681801e-07  4.08067594e+02 -4.79426954e-07 -4.84372503e-07]\n",
      " [-1.07788998e-05 -1.07831999e-05 -1.07864405e-05 -1.07827082e-05]\n",
      " [-8.77440039e-06 -8.77290722e-06 -8.77530722e-06 -8.78020138e-06]\n",
      " [-5.65412767e-06 -5.65568359e-06 -5.65425876e-06 -5.64860762e-06]\n",
      " [-1.93627432e-06 -1.93545316e-06 -1.93807569e-06 -1.94351771e-06]\n",
      " [-8.74027948e-07 -8.67890226e-07 -8.70238582e-07  6.09710501e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.98111352e-07 -1.96590109e-07  2.68525876e-06 -2.02601306e-07]\n",
      " [-1.99482120e-07  4.29544846e+02 -1.99819692e-07 -2.01397602e-07]\n",
      " [-6.76313883e-06 -6.76168332e-06 -6.75833925e-06 -6.76745585e-06]\n",
      " [-5.02318172e-06 -5.01597967e-06 -5.01786743e-06 -5.02499478e-06]\n",
      " [-2.97291820e-06 -2.96139867e-06 -2.96139867e-06 -2.97202295e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.17705327e-07 -2.18290490e-07  9.77859063e-07 -2.14928927e-07]\n",
      " [-6.01953454e-08 -5.98976424e-08  3.24659074e-04 -5.98501999e-08]\n",
      " [-6.98756968e-08 -6.97903497e-08  6.84464497e-02 -7.02844487e-08]\n",
      " [-7.99006788e-08  4.52152480e+02 -7.99860014e-08 -8.02887704e-08]\n",
      " [-3.14505992e-06 -3.13585744e-06 -3.14213295e-06 -3.14706688e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.99900000e-08 -1.99900000e-08 -2.00753729e-08 -1.99900000e-08]\n",
      " [-6.98188482e-08 -6.97903497e-08 -6.98849809e-08 -6.04514827e-08]\n",
      " [-3.00367395e-08 -2.99700100e-08 -2.99700100e-08 -3.37851731e-08]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-2.99700100e-08  4.75949990e+02 -1.99995000e-08 -2.00184896e-08]\n",
      " [-1.42493541e-06 -1.42686156e-06 -1.42794030e-06 -1.43647904e-06]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-3.99400400e-08 -3.01219245e-08 -2.99795100e-08 -3.99400400e-08]\n",
      " [-1.00095000e-08 -1.99900000e-08 -1.00000000e-08 -1.00095000e-08]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e-08 -1.00000000e-08 -1.00000000e-08  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [-1.00000000e-08  5.01000000e+02 -1.00000000e-08  0.00000000e+00]\n",
      " [-8.98000434e-07 -8.98000434e-07 -9.02978589e-07 -9.00580497e-07]\n",
      " [-3.48835452e-07 -3.49702664e-07 -3.46036739e-07 -3.53770815e-07]\n",
      " [-1.21251183e-07 -1.19967005e-07 -1.29222853e-07 -1.29383819e-07]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 -1.00000000e-08]\n",
      " [-1.00000000e-08  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
      "Cantidad exito: 44607  de  50000 ; Ratio de exito= 89.214 %\n"
     ]
    }
   ],
   "source": [
    "# Caso 2 - tabla 8x8\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "gym_env = \"FrozenLake-v1\"\n",
    "environment = gym.make(gym_env, is_slippery=False,map_name=\"8x8\")\n",
    "environment.reset()\n",
    "\n",
    "nb_states = environment.observation_space.n\n",
    "nb_actions = environment.action_space.n \n",
    "qtable = np.zeros((nb_states, nb_actions))\n",
    "\n",
    "# Artificio de agregar un valor diferente de cero inicial\n",
    "qtable = qtable + 0.0  \n",
    "\n",
    "\n",
    "# Hiperparametros\n",
    "episodes = 50000        # numero episodios\n",
    "alpha = 0.001            # Learning rate\n",
    "gamma = 0.95           # Discount factor\n",
    "epsilon = 1.0          # Amount of randomness in the action selection\n",
    "epsilon_decay = 0.02   # Fixed amount to decrease\n",
    "max_ii = 150            # limite de pasos por episodio\n",
    "\n",
    "print('Q-Tabla inicial:')\n",
    "print(qtable)\n",
    "\n",
    "# Llevar conteo de casos de exito\n",
    "cantidad_exitos = 0\n",
    "\n",
    "# guardar casos de exito\n",
    "camino_exitoso = []\n",
    "\n",
    "# Entrenamiento\n",
    "for ii in range(episodes):\n",
    "    \n",
    "    # Borrar salida\n",
    "    if(ii % 80 == 0):\n",
    "        clear_output()\n",
    "        \n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # camino seguido en episodio \n",
    "    camino_episodio_actual = []\n",
    "    \n",
    "    # tabla previa\n",
    "    qtable_anterior = qtable.copy()\n",
    "    \n",
    "    # flag para indicar si tuvo o no exito en episodio actual\n",
    "    exito_actual = 0\n",
    "    \n",
    "    # entrenar y actualizar matriz Q\n",
    "    while not done:\n",
    "        \n",
    "        # valor aleatorio entre 0 y 1\n",
    "        rnd = np.random.random()\n",
    "\n",
    "        # si se cumple rnd < epsilon tomar una accion aleatoria\n",
    "        if rnd < epsilon:\n",
    "            action = environment.action_space.sample()\n",
    "            \n",
    "        # si no es aleatorio, seleccionar la opcion con Q mas alto\n",
    "        else:\n",
    "            vector = qtable[state]\n",
    "            action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "             \n",
    "        # aplicar accion\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        # guardar camino\n",
    "        camino_episodio_actual.append((state,action,new_state))\n",
    "        \n",
    "        ################\n",
    "        \n",
    "        # Valor de recompensa en caso de lograr exitosamente descubrir el objetivo\n",
    "        reward_exito = 1\n",
    "        \n",
    "        # En caso de no llegar a recomensa y seguir en camino de aprendizaje penalizar cada paso\n",
    "        if reward < reward_exito:\n",
    "            reward = reward - 1e-5\n",
    "        \n",
    "        # En caso que se tenga exito en descubrir el objetivo - brindar una recompensa adicional mayor\n",
    "        if reward >= reward_exito:\n",
    "            reward = reward + 500\n",
    "        \n",
    "        ####################\n",
    "        \n",
    "        # Actualiza el valor de Q(s,a) segun accion y estado\n",
    "        qtable[state, action] = qtable[state, action] + \\\n",
    "                                alpha * (reward + gamma * np.max(qtable[new_state]) - qtable[state, action])\n",
    "        \n",
    "        # actualiza estado actual\n",
    "        state = new_state\n",
    "        \n",
    "        ###################\n",
    "        ## Exito conseguido\n",
    "        \n",
    "        if reward >= reward_exito:\n",
    "            \n",
    "            # Guardar camino exitoso\n",
    "            camino_exitoso.append(camino_episodio_actual)\n",
    "            \n",
    "            # Indicar que se tuvo exito\n",
    "            exito_actual = 1\n",
    "            \n",
    "            # Informativo\n",
    "            print('Exito en episodio:',ii,'; pasos:',pasos_ii,'; estado:',state,'; reward:',reward)\n",
    "        \n",
    "        ##################\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        \n",
    "        # En caso se exceda de la cantidad maximas de pasos en un episodio salir de bucle\n",
    "        if(pasos_ii > max_ii):\n",
    "            qtable = qtable_anterior.copy()\n",
    "            break\n",
    "    \n",
    "    ########################\n",
    "    #### fin episodio  #####\n",
    "    \n",
    "    # Contador de exitos\n",
    "    cantidad_exitos += exito_actual\n",
    "    \n",
    "    # Actualizar epsilon\n",
    "    epsilon = max(epsilon - epsilon_decay, 0)\n",
    "    \n",
    "    # Actualizar valor de tabla anterior\n",
    "    qtable_anterior = qtable.copy()\n",
    "\n",
    "print()\n",
    "print('===========================================')\n",
    "print('Q-Tabla final:')\n",
    "print(qtable)\n",
    "\n",
    "print (\"Cantidad exito:\",cantidad_exitos,\" de \",episodes,\"; Ratio de exito=\",np.round(100.*(cantidad_exitos/episodes),3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff614325",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:42:12.567808Z",
     "start_time": "2022-11-29T16:42:12.553853Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44607"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de caminos exitosos\n",
    "len(camino_exitoso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "32149eda",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:42:13.202917Z",
     "start_time": "2022-11-29T16:42:13.196917Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tupla se lee: (state_actual, action, new_state)\n",
      "Indice i: -1  ; cantidad pasos: 14\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 2, 1),\n",
       " (1, 1, 9),\n",
       " (9, 2, 10),\n",
       " (10, 2, 11),\n",
       " (11, 2, 12),\n",
       " (12, 2, 13),\n",
       " (13, 1, 21),\n",
       " (21, 2, 22),\n",
       " (22, 2, 23),\n",
       " (23, 1, 31),\n",
       " (31, 1, 39),\n",
       " (39, 1, 47),\n",
       " (47, 1, 55),\n",
       " (55, 1, 63)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver cada camino seguido\n",
    "\n",
    "# cada tupla se lee: (state_actual, action, new_state)\n",
    "i = -1\n",
    "\n",
    "print('La tupla se lee: (state_actual, action, new_state)')\n",
    "print('Indice i:',i,' ; cantidad pasos:',len(camino_exitoso[i]))\n",
    "camino_exitoso[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a143e330",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:42:34.274296Z",
     "start_time": "2022-11-29T16:42:14.329801Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de animaciones a realizar: 5\n",
      "** ÉXITO ** Episode: 0 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "** ÉXITO ** Episode: 1 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "** ÉXITO ** Episode: 2 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "** ÉXITO ** Episode: 3 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "** ÉXITO ** Episode: 4 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Casos exito: 5 ; Ratio de exito= 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# [Ver animacion] Aplicar a \"Q\" entrenado\n",
    "\n",
    "environment = gym.make(gym_env, is_slippery=False,map_name=\"8x8\",render_mode=\"human\")\n",
    "environment.reset()\n",
    "\n",
    "# Cantidad de simulaciones\n",
    "episodes = 5\n",
    "print('Cantidad de animaciones a realizar:',episodes)\n",
    "\n",
    "# Registro de simulaciones exitosas\n",
    "nb_success = 0\n",
    "\n",
    " # limite de pasos por episodio\n",
    "max_ii = 100\n",
    "\n",
    "environment.render()\n",
    "\n",
    "# Evaluacion\n",
    "for ii in range(episodes):\n",
    "\n",
    "    # Inicializar entorno\n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # Hasta que finalice o se atore\n",
    "    while not done:\n",
    "        \n",
    "        # Seleccionar accion\n",
    "        vector = qtable[state]\n",
    "        action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "\n",
    "        # Aplicar accion y ver nuevos estados\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        #print('Estado:',new_state,'; Recompensa:',reward,'; Finalizacion:',done)\n",
    "        \n",
    "        # Actualizar estado\n",
    "        state = new_state\n",
    "        \n",
    "        # information\n",
    "        #print('Episode:',ii,'; num pasos:',pasos_ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "        \n",
    "        # Si se da recomensa, se ganó el juego\n",
    "        if reward >= reward_exito:\n",
    "            nb_success += 1\n",
    "            print('** ÉXITO **','Episode:',ii,'; num pasos:',pasos_ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "            break\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        if(pasos_ii > max_ii):\n",
    "            break\n",
    "\n",
    "print (\"Casos exito:\",nb_success,\"; Ratio de exito=\",np.round(100.*(nb_success/episodes),1),\"%\")\n",
    "environment.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d114b50",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### Taxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b4efbb",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Aplicacion en el entorno taxi: https://www.gymlibrary.dev/environments/toy_text/taxi/#arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6abaf3db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:27:08.293601Z",
     "start_time": "2022-11-29T16:24:00.739361Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exito en episodio: 79920 ; pasos: 11 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79921 ; pasos: 11 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79922 ; pasos: 15 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79923 ; pasos: 27 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79924 ; pasos: 11 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79925 ; pasos: 12 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79926 ; pasos: 9 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79927 ; pasos: 10 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79928 ; pasos: 15 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79929 ; pasos: 14 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79930 ; pasos: 9 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79931 ; pasos: 14 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79932 ; pasos: 11 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79933 ; pasos: 12 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79934 ; pasos: 12 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79935 ; pasos: 12 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79936 ; pasos: 8 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79937 ; pasos: 20 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79938 ; pasos: 19 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79939 ; pasos: 10 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79940 ; pasos: 7 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79941 ; pasos: 10 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79942 ; pasos: 10 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79943 ; pasos: 10 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79944 ; pasos: 15 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79945 ; pasos: 20 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79946 ; pasos: 13 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79947 ; pasos: 8 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79948 ; pasos: 29 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79949 ; pasos: 17 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79950 ; pasos: 9 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79951 ; pasos: 8 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79952 ; pasos: 13 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79953 ; pasos: 9 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79954 ; pasos: 27 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79955 ; pasos: 11 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79956 ; pasos: 13 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79957 ; pasos: 11 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79958 ; pasos: 12 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79959 ; pasos: 12 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79960 ; pasos: 11 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79961 ; pasos: 9 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79962 ; pasos: 13 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79963 ; pasos: 12 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79964 ; pasos: 12 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79965 ; pasos: 16 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79966 ; pasos: 18 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79967 ; pasos: 9 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79968 ; pasos: 15 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79969 ; pasos: 6 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79970 ; pasos: 9 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79971 ; pasos: 8 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79972 ; pasos: 8 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79973 ; pasos: 11 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79974 ; pasos: 10 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79975 ; pasos: 12 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79976 ; pasos: 10 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79977 ; pasos: 12 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79978 ; pasos: 7 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79979 ; pasos: 15 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79980 ; pasos: 23 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79981 ; pasos: 9 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79982 ; pasos: 10 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79983 ; pasos: 9 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79984 ; pasos: 13 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79985 ; pasos: 12 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79986 ; pasos: 9 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79987 ; pasos: 9 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79988 ; pasos: 14 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79989 ; pasos: 14 ; estado: 0 ; reward: 520\n",
      "Exito en episodio: 79990 ; pasos: 27 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79991 ; pasos: 19 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79992 ; pasos: 17 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79993 ; pasos: 19 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79994 ; pasos: 7 ; estado: 410 ; reward: 520\n",
      "Exito en episodio: 79995 ; pasos: 8 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79996 ; pasos: 12 ; estado: 85 ; reward: 520\n",
      "Exito en episodio: 79997 ; pasos: 16 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79998 ; pasos: 22 ; estado: 475 ; reward: 520\n",
      "Exito en episodio: 79999 ; pasos: 18 ; estado: 85 ; reward: 520\n",
      "\n",
      "===========================================\n",
      "Q-Tabla final:\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [-1.93239749e+00 -1.93222575e+00 -1.93151606e+00 -1.93222832e+00\n",
      "   1.37258062e+02 -1.94057285e+00]\n",
      " [-7.55218901e-01 -7.54422150e-01 -7.54963241e-01 -7.54422150e-01\n",
      "   3.28143819e+02 -7.58576756e-01]\n",
      " ...\n",
      " [-2.46474860e-01 -1.47733832e-01 -2.46463614e-01 -2.46718118e-01\n",
      "  -2.49825391e-01 -2.49840568e-01]\n",
      " [-1.01249797e+00 -1.01291552e+00 -1.01249797e+00 -1.01247182e+00\n",
      "  -1.01742879e+00 -1.01742879e+00]\n",
      " [-1.99995000e-03 -1.99995000e-03 -1.99995000e-03  1.30145233e-01\n",
      "  -1.00000000e-02 -1.00000000e-02]]\n",
      "Cantidad exito: 64984  de  80000 ; Ratio de exito= 81.23 %\n"
     ]
    }
   ],
   "source": [
    "# Caso 1\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "gym_env = \"Taxi-v3\"\n",
    "environment = gym.make(gym_env)\n",
    "environment.reset()\n",
    "\n",
    "nb_states = environment.observation_space.n\n",
    "nb_actions = environment.action_space.n \n",
    "qtable = np.zeros((nb_states, nb_actions))\n",
    "\n",
    "# Artificio de agregar un valor diferente de cero inicial\n",
    "qtable = qtable + 0.0  \n",
    "\n",
    "# Hiperparametros\n",
    "episodes = 80000        # numero episodios\n",
    "alpha = 0.001            # Learning rate\n",
    "gamma = 0.95           # Discount factor\n",
    "epsilon = 1.0          # Amount of randomness in the action selection\n",
    "epsilon_decay = 0.02   # Fixed amount to decrease\n",
    "max_ii = 150            # limite de pasos por episodio\n",
    "\n",
    "print('Q-Tabla inicial:')\n",
    "print(qtable)\n",
    "\n",
    "# Llevar conteo de casos de exito\n",
    "cantidad_exitos = 0\n",
    "\n",
    "# guardar casos de exito\n",
    "camino_exitoso = []\n",
    "\n",
    "# Entrenamiento\n",
    "for ii in range(episodes):\n",
    "    \n",
    "    # Borrar salida\n",
    "    if(ii % 80 == 0):\n",
    "        clear_output()\n",
    "    \n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # camino seguido en episodio \n",
    "    camino_episodio_actual = []\n",
    "    \n",
    "    # tabla previa\n",
    "    qtable_anterior = qtable.copy()\n",
    "    \n",
    "    # flag para indicar si tuvo o no exito en episodio actual\n",
    "    exito_actual = 0\n",
    "    \n",
    "    # entrenar y actualizar matriz Q\n",
    "    while not done:\n",
    "        \n",
    "        # valor aleatorio entre 0 y 1\n",
    "        rnd = np.random.random()\n",
    "\n",
    "        # si se cumple rnd < epsilon tomar una accion aleatoria\n",
    "        if rnd < epsilon:\n",
    "            action = environment.action_space.sample()\n",
    "            \n",
    "        # si no es aleatorio, seleccionar la opcion con Q mas alto\n",
    "        else:\n",
    "            vector = qtable[state]\n",
    "            action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "             \n",
    "        # aplicar accion\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        # guardar camino\n",
    "        camino_episodio_actual.append((state,action,new_state))\n",
    "        \n",
    "        ################\n",
    "        \n",
    "        # Valor de recompensa en caso de lograr exitosamente descubrir el objetivo\n",
    "        reward_exito = 20\n",
    "        \n",
    "        # En caso de no llegar a recomensa y seguir en camino de aprendizaje penalizar cada paso\n",
    "        if reward < reward_exito:\n",
    "            reward = reward - 0\n",
    "        \n",
    "        # En caso que se tenga exito en descubrir el objetivo - brindar una recompensa adicional mayor\n",
    "        if reward >= reward_exito:\n",
    "            reward = reward + 500\n",
    "        \n",
    "        ####################\n",
    "        \n",
    "        # Actualiza el valor de Q(s,a) segun accion y estado\n",
    "        qtable[state, action] = qtable[state, action] + \\\n",
    "                                alpha * (reward + gamma * np.max(qtable[new_state]) - qtable[state, action])\n",
    "        \n",
    "        # actualiza estado actual\n",
    "        state = new_state\n",
    "        \n",
    "        ###################\n",
    "        ## Exito conseguido\n",
    "        \n",
    "        if reward >= reward_exito:\n",
    "            \n",
    "            # Guardar camino exitoso\n",
    "            camino_exitoso.append(camino_episodio_actual)\n",
    "            \n",
    "            # Indicar que se tuvo exito\n",
    "            exito_actual = 1\n",
    "            \n",
    "            # Informativo\n",
    "            print('Exito en episodio:',ii,'; pasos:',pasos_ii,'; estado:',state,'; reward:',reward)\n",
    "        \n",
    "        ##################\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        \n",
    "        # En caso se exceda de la cantidad maximas de pasos en un episodio salir de bucle\n",
    "        if(pasos_ii > max_ii):\n",
    "            #qtable = qtable_anterior.copy()\n",
    "            break\n",
    "    \n",
    "    ########################\n",
    "    #### fin episodio  #####\n",
    "    \n",
    "    # Contador de exitos\n",
    "    cantidad_exitos += exito_actual\n",
    "    \n",
    "    # Actualizar epsilon\n",
    "    epsilon = max(epsilon - epsilon_decay, 0)\n",
    "    \n",
    "    # Actualizar valor de tabla anterior\n",
    "    qtable_anterior = qtable.copy()\n",
    "\n",
    "print()\n",
    "print('===========================================')\n",
    "print('Q-Tabla final:')\n",
    "print(qtable)\n",
    "\n",
    "print (\"Cantidad exito:\",cantidad_exitos,\" de \",episodes,\"; Ratio de exito=\",np.round(100.*(cantidad_exitos/episodes),3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf26c7e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:29:11.550713Z",
     "start_time": "2022-11-29T16:29:11.545713Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64984"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de caminos exitosos\n",
    "len(camino_exitoso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "168359ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:29:12.522748Z",
     "start_time": "2022-11-29T16:29:12.516735Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tupla se lee: (state_actual, action, new_state)\n",
      "Indice i: -1  ; cantidad pasos: 19\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(421, 2, 441),\n",
       " (441, 2, 441),\n",
       " (441, 0, 441),\n",
       " (441, 3, 421),\n",
       " (421, 1, 321),\n",
       " (321, 1, 221),\n",
       " (221, 1, 121),\n",
       " (121, 3, 101),\n",
       " (101, 1, 1),\n",
       " (1, 4, 17),\n",
       " (17, 0, 117),\n",
       " (117, 0, 217),\n",
       " (217, 2, 237),\n",
       " (237, 2, 257),\n",
       " (257, 2, 277),\n",
       " (277, 2, 297),\n",
       " (297, 1, 197),\n",
       " (197, 1, 97),\n",
       " (97, 5, 85)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver cada camino seguido\n",
    "\n",
    "# cada tupla se lee: (state_actual, action, new_state)\n",
    "i = -1\n",
    "\n",
    "print('La tupla se lee: (state_actual, action, new_state)')\n",
    "print('Indice i:',i,' ; cantidad pasos:',len(camino_exitoso[i]))\n",
    "camino_exitoso[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aed5f7d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T16:29:13.968212Z",
     "start_time": "2022-11-29T16:29:13.800342Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de animaciones a realizar: 100\n",
      "** ÉXITO ** Episode: 1 ; num pasos: 12 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 2 ; num pasos: 10 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 3 ; num pasos: 10 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 4 ; num pasos: 10 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 5 ; num pasos: 13 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 6 ; num pasos: 11 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 8 ; num pasos: 13 ; action: 5 ; state: 475 ; reward: 20\n",
      "** ÉXITO ** Episode: 9 ; num pasos: 13 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 10 ; num pasos: 11 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 11 ; num pasos: 15 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 13 ; num pasos: 15 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 14 ; num pasos: 10 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 17 ; num pasos: 11 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 19 ; num pasos: 7 ; action: 5 ; state: 475 ; reward: 20\n",
      "** ÉXITO ** Episode: 20 ; num pasos: 11 ; action: 5 ; state: 475 ; reward: 20\n",
      "** ÉXITO ** Episode: 21 ; num pasos: 13 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 22 ; num pasos: 11 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 24 ; num pasos: 14 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 25 ; num pasos: 10 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 26 ; num pasos: 13 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 28 ; num pasos: 12 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 29 ; num pasos: 13 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 30 ; num pasos: 12 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 32 ; num pasos: 9 ; action: 5 ; state: 475 ; reward: 20\n",
      "** ÉXITO ** Episode: 34 ; num pasos: 8 ; action: 5 ; state: 475 ; reward: 20\n",
      "** ÉXITO ** Episode: 35 ; num pasos: 9 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 38 ; num pasos: 7 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 39 ; num pasos: 14 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 41 ; num pasos: 11 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 42 ; num pasos: 15 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 44 ; num pasos: 6 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 45 ; num pasos: 10 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 46 ; num pasos: 11 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 47 ; num pasos: 10 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 50 ; num pasos: 12 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 52 ; num pasos: 14 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 53 ; num pasos: 10 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 54 ; num pasos: 11 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 56 ; num pasos: 9 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 57 ; num pasos: 14 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 58 ; num pasos: 8 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 60 ; num pasos: 10 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 61 ; num pasos: 10 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 62 ; num pasos: 17 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 63 ; num pasos: 16 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 64 ; num pasos: 12 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 65 ; num pasos: 9 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 67 ; num pasos: 12 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 68 ; num pasos: 10 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 69 ; num pasos: 12 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 70 ; num pasos: 10 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 71 ; num pasos: 13 ; action: 5 ; state: 475 ; reward: 20\n",
      "** ÉXITO ** Episode: 72 ; num pasos: 12 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 73 ; num pasos: 11 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 74 ; num pasos: 12 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 75 ; num pasos: 13 ; action: 5 ; state: 475 ; reward: 20\n",
      "** ÉXITO ** Episode: 76 ; num pasos: 10 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 77 ; num pasos: 8 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 78 ; num pasos: 9 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 79 ; num pasos: 13 ; action: 5 ; state: 475 ; reward: 20\n",
      "** ÉXITO ** Episode: 80 ; num pasos: 6 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 81 ; num pasos: 13 ; action: 5 ; state: 475 ; reward: 20\n",
      "** ÉXITO ** Episode: 82 ; num pasos: 13 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 83 ; num pasos: 10 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 84 ; num pasos: 9 ; action: 5 ; state: 0 ; reward: 20\n",
      "** ÉXITO ** Episode: 85 ; num pasos: 14 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 88 ; num pasos: 9 ; action: 5 ; state: 475 ; reward: 20\n",
      "** ÉXITO ** Episode: 90 ; num pasos: 11 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 93 ; num pasos: 5 ; action: 5 ; state: 410 ; reward: 20\n",
      "** ÉXITO ** Episode: 94 ; num pasos: 14 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 95 ; num pasos: 12 ; action: 5 ; state: 85 ; reward: 20\n",
      "** ÉXITO ** Episode: 99 ; num pasos: 14 ; action: 5 ; state: 475 ; reward: 20\n",
      "Casos exito: 72 ; Ratio de exito= 72.0 %\n"
     ]
    }
   ],
   "source": [
    "# [Ver animacion] Aplicar a \"Q\" entrenado\n",
    "\n",
    "environment = gym.make(gym_env)\n",
    "environment.reset()\n",
    "\n",
    "# Cantidad de simulaciones\n",
    "episodes = 100\n",
    "print('Cantidad de animaciones a realizar:',episodes)\n",
    "\n",
    "# Registro de simulaciones exitosas\n",
    "nb_success = 0\n",
    "\n",
    " # limite de pasos por episodio\n",
    "max_ii = 150\n",
    "\n",
    "\n",
    "# Evaluacion\n",
    "for ii in range(episodes):\n",
    "\n",
    "    # Inicializar entorno\n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # Hasta que finalice o se atore\n",
    "    while not done:\n",
    "        \n",
    "        # Seleccionar accion\n",
    "        vector = qtable[state]\n",
    "        action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "\n",
    "        # Aplicar accion y ver nuevos estados\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        #print('Estado:',new_state,'; Recompensa:',reward,'; Finalizacion:',done)\n",
    "        \n",
    "        # Actualizar estado\n",
    "        state = new_state\n",
    "        \n",
    "        # information\n",
    "        #print('Episode:',ii,'; num pasos:',pasos_ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "        \n",
    "        # Si se da recomensa, se ganó el juego\n",
    "        if reward >= reward_exito:\n",
    "            nb_success += 1\n",
    "            print('** ÉXITO **','Episode:',ii,'; num pasos:',pasos_ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "            break\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        if(pasos_ii > max_ii):\n",
    "            break\n",
    "\n",
    "print (\"Casos exito:\",nb_success,\"; Ratio de exito=\",np.round(100.*(nb_success/episodes),1),\"%\")\n",
    "environment.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
