{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6801b3",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es el brindar ejemplos de acceso y uso de ambientes para simulación orientados al Reinforcement Learning (Aprendizaje por reforzamiento) mediante la libreria Gym. Link con documentacion: https://www.gymlibrary.dev/content/basic_usage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac9bde74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T04:35:13.274579Z",
     "start_time": "2022-11-29T04:35:12.696336Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Librerias\n",
    "\n",
    "import gym\n",
    "import keyboard\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f0ec9",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simulador GymAI > Ambientes diversos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf115f4",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Escenario: LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f0426c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:07:27.333502Z",
     "start_time": "2022-11-28T03:07:23.407370Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: LunarLander-v2\n",
      "Acciones del espacio: Discrete(4)\n",
      "muestra ::  0\n",
      "muestra ::  3\n",
      "muestra ::  2\n",
      "muestra ::  1\n",
      "muestra ::  1\n",
      "muestra ::  3\n",
      "muestra ::  0\n",
      "muestra ::  2\n",
      "muestra ::  0\n",
      "muestra ::  0\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: -2.497033478022092 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: 0.3028158191380623 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -4.084324611699333 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.06415158466822277 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -4.230430849374488 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: 0.012746637376268383 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -2.8209334305346827 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: 0.44435753911477605 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.34957934879241637 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: 1.1449635758303611 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -2.2152398545693925 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: 1.199374137458393 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: 0.5782678686134091 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: -0.39931580881619655 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: -1.0205897198816831 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -2.729823545860671 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: 0.973169224956963 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.8272269772758125 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: -4.934150697483164 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 0.6306953972599001 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: 0.8484956601110138 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.10775034724173338 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.30228160250740643 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -3.8740962831673924 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -1.5181619457291322 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: -0.7609956752394851 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: -2.1027271739572755 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: -2.478108164921507 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.3946844182438827 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -1.5072828837337966 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -1.6521914239254443 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -3.1332412960061604 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -2.4452637053411364 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: -0.6616309017342974 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -1.8649748393497987 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: -3.095805060199693 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: -1.1563142141057756 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: -3.3463245673891877 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: -1.9385396426059913 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -3.505726530843218 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: -3.4463851406184163 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -2.7413437001413 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -1.8424036798431007 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: -1.8571298325692271 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: -1.5972672490282196 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: -2.317262857843957 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: -3.103316515477604 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: -2.1731876155705834 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: -2.05800974868298 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: -3.0253473947238545 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1 - de ambiente simulacion\n",
    "\n",
    "gym_env = \"LunarLander-v2\"\n",
    "env = gym.make(gym_env, render_mode=\"human\")\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "    \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7828ddd",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Escenario: CartPole-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c8515c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:07:38.322030Z",
     "start_time": "2022-11-28T03:07:36.248554Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CartPole-v1\n",
      "Acciones del espacio: Discrete(2)\n",
      "muestra ::  0\n",
      "muestra ::  1\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "muestra ::  0\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "muestra ::  0\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: 1.0 ;term: True ;trun: False ;info: {}\n",
      "------- Finalizado (Consiguió objetivo) ---------------\n",
      "i: 11 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: 1.0 ;term: True ;trun: False ;info: {}\n",
      "------- Finalizado (Consiguió objetivo) ---------------\n",
      "i: 47 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 2 - de ambiente simulacion\n",
    "\n",
    "gym_env = \"CartPole-v1\"\n",
    "env = gym.make(gym_env, render_mode=\"human\")\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "\n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4639c9",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Escenario: BipedalWalker-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdbf029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:07:48.152005Z",
     "start_time": "2022-11-28T03:07:46.115744Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: BipedalWalker-v3\n",
      "Acciones del espacio: Box(-1.0, 1.0, (4,), float32)\n",
      "muestra ::  [ 0.5479121  -0.12224312  0.71719587  0.39473605]\n",
      "muestra ::  [-0.8116453  0.9512447  0.5222794  0.5721286]\n",
      "muestra ::  [-0.74377275 -0.09922812 -0.25840396  0.85353   ]\n",
      "muestra ::  [ 0.28773025  0.64552325 -0.1131716  -0.5455226 ]\n",
      "muestra ::  [ 0.10916957 -0.8723655   0.65526235  0.2633288 ]\n",
      "muestra ::  [ 0.5161755  -0.29094806  0.94139606  0.78624225]\n",
      "muestra ::  [ 0.556767  -0.6107226 -0.066558  -0.9123925]\n",
      "muestra ::  [-0.69142103  0.3660979   0.4895243   0.9350195 ]\n",
      "muestra ::  [-0.34834927 -0.2590806  -0.06088838 -0.6210573 ]\n",
      "muestra ::  [-0.740157   -0.04859015 -0.5461813   0.33962798]\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: -0.03677048385639867 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: -0.12128347212386865 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -0.12639417488376062 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.18618398785591125 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -0.1334285677472762 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: -0.12666408969958506 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -0.17000708866119382 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: -0.024435176074504857 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.033851756831012554 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: 0.05692235102256376 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -0.09035675211747723 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: -0.046714869966108415 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: 0.05029917001289508 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: 0.06583368244767189 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: 0.03515792099634925 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -0.013376621777813822 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: -0.048433364883065225 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.008062145233154296 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: 0.03817116846392672 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 0.022094737824052572 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: 0.0020779402529188078 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.1674081994270273 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.14762182070811472 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -0.09895633501807967 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -0.006356225719053359 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: 0.06988523552566767 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: 0.045934727206826204 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: 0.042538841515779496 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.047774908423423766 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -0.026592801779508592 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -0.21871826105316716 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -0.11595947506030282 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -0.11892899042616405 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: -0.13629220004876336 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -0.056696600099403464 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: 0.009465642149247345 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: 0.032888669649761115 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: 0.08048467103640358 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: 0.002112373590469358 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -0.005413786649703978 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: 0.0285516682288908 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -0.0633392872015647 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -0.010249168938644346 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: 0.07046689116954803 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: 0.11549892012278003 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: 0.12938673095902042 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: 0.16951408779621124 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: 0.16054574155807494 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: 0.22392252137263494 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: 0.16408513531088828 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 3 - de ambiente simulacion\n",
    "\n",
    "gym_env = \"BipedalWalker-v3\"\n",
    "env = gym.make(gym_env, render_mode=\"human\")\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "\n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df69b124",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Simulador GymAI > Box2D > Car Racing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478cc9e6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Caso de accion \"continua\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ece7103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:08:02.484932Z",
     "start_time": "2022-11-28T03:08:00.207194Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Acciones del espacio: Box([-1.  0.  0.], 1.0, (3,), float32)\n",
      "muestra ::  [0.5479121  0.43887845 0.85859793]\n",
      "muestra ::  [0.39473605 0.09417735 0.97562236]\n",
      "muestra ::  [0.5222794  0.7860643  0.12811363]\n",
      "muestra ::  [-0.09922812  0.37079802  0.92676497]\n",
      "muestra ::  [0.28773025 0.8227616  0.4434142 ]\n",
      "muestra ::  [-0.5455226   0.5545848   0.06381726]\n",
      "muestra ::  [0.65526235 0.6316644  0.75808775]\n",
      "muestra ::  [-0.29094806  0.970698    0.8931211 ]\n",
      "muestra ::  [0.556767   0.19463871 0.466721  ]\n",
      "muestra ::  [-0.9123925   0.1542895   0.68304896]\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: 6.967137809187279 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 3.4335689045936393 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 4 (opcion continua) - de ambiente simulacion de carros\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "gym_env = \"CarRacing-v2\"\n",
    "env = gym.make(gym_env, render_mode=\"human\",continuous=True,lap_complete_percent=1.00)\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "    \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c5e1a",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Caso de accion \"discreta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2b8987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:08:11.094248Z",
     "start_time": "2022-11-28T03:08:08.763953Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Acciones del espacio: Discrete(5)\n",
      "muestra ::  0\n",
      "muestra ::  3\n",
      "muestra ::  3\n",
      "muestra ::  2\n",
      "muestra ::  2\n",
      "muestra ::  4\n",
      "muestra ::  0\n",
      "muestra ::  3\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: 6.967137809187279 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -0.10000000000000009 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -0.10000000000000009 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -0.10000000000000009 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: 3.4335689045936397 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 4 (opcion discreta) - de ambiente simulacion de carros\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "gym_env = \"CarRacing-v2\"\n",
    "env = gym.make(gym_env, render_mode=\"human\",continuous=False,lap_complete_percent=1.00)\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "    \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8e763f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:08:29.085499Z",
     "start_time": "2022-11-28T03:08:28.962160Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ver un estado segun ambiente\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(observation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a266ca",
   "metadata": {
    "hidden": true
   },
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3407be0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Simulacion de interaccion con teclado**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dcb281",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1) Simulador sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1772814d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T22:47:08.516093Z",
     "start_time": "2022-11-15T22:46:57.606946Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Simulador de Carro con ingreso por teclado\n",
    "\n",
    "import pygame\n",
    "from gym.utils.play import play\n",
    "\n",
    "# Mapeo de teclados - modo discreto\n",
    "mapping = {(pygame.K_SPACE,): 0,(pygame.K_RIGHT,): 1, (pygame.K_LEFT,): 2,(pygame.K_UP,): 3,(pygame.K_DOWN,): 4}\n",
    "\n",
    "# Simular con interaccion por teclado de computadora\n",
    "play(gym.make(\"CarRacing-v2\",render_mode=\"rgb_array_list\",continuous=False,lap_complete_percent=1.00), keys_to_action=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c766ba",
   "metadata": {
    "hidden": true
   },
   "source": [
    "2) Simulacion por teclado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f0dc2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T04:48:00.353910Z",
     "start_time": "2022-11-16T04:47:49.630662Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Porcentaje a completar: 85.0 %\n",
      "Acciones del espacio: Discrete(5)\n",
      "-------------------------------------\n",
      "[INFO] Presione tecla para finalizar:  s\n",
      "[INICIO] Presione la tecla \"i\" para iniciar\n",
      "Se ha iniciado la simulacion\n",
      " *** Se presiono finalizar ***\n"
     ]
    }
   ],
   "source": [
    "# Simulador de Carro con ingreso por teclado\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "perc_complete = 0.85\n",
    "gym_env = \"CarRacing-v2\"\n",
    "\n",
    "env = gym.make(gym_env, render_mode=\"human\",\n",
    "               max_episode_steps=10000,\n",
    "               continuous=False,\n",
    "               lap_complete_percent=perc_complete)\n",
    "\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print('Porcentaje a completar:',np.round(100.*perc_complete,1),'%')\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "print('-------------------------------------')\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Tecla para finalizar\n",
    "tecla_finalizar = \"s\"\n",
    "print('[INFO] Presione tecla para finalizar: ',tecla_finalizar)\n",
    "\n",
    "# Informacion de teclados:\n",
    "## DERECHA: ir a la derecha (incluye girar)\n",
    "## IZQUIERDA: ir a la izquierda (incluye girar)\n",
    "## ARRIBA: avanzar aumentando velocidad\n",
    "## ABAJO: Reduce velocidad\n",
    "## TECLA SALIR definido arriba ver codigo lineas arriba\n",
    "\n",
    "# Parametro de finalizacion - en caso se equivoque mucho finalizar ya!!\n",
    "min_reward_to_finish = 12.5\n",
    "steps_batch = 300\n",
    "steps_to_finish = steps_batch\n",
    "reward_to_finish = 0\n",
    "finish_simulation = False\n",
    "\n",
    "#############################\n",
    "\n",
    "print('[INICIO] Presione la tecla \"i\" para iniciar')\n",
    "while(not keyboard.is_pressed(\"i\")):\n",
    "    pass\n",
    "\n",
    "print('Se ha iniciado la simulacion')\n",
    "observation, info = env.reset()\n",
    "\n",
    "#############################\n",
    "\n",
    "# Inicializar parametros\n",
    "time_start = time.time()\n",
    "reward_global = 0\n",
    "pasos_ciclo = 0\n",
    "num_ciclo = 1\n",
    "\n",
    "\n",
    "# Simulacion\n",
    "while True:\n",
    "    \n",
    "    # Accion por defecto en caso no se presione nada\n",
    "    accion = 0\n",
    "    \n",
    "    # En caso se presione alguna tecla en especifico\n",
    "    if keyboard.is_pressed(\"flecha derecha\"):\n",
    "        accion = 1\n",
    "    elif keyboard.is_pressed(\"flecha izquierda\"):\n",
    "        accion = 2\n",
    "    elif keyboard.is_pressed(\"flecha arriba\"):\n",
    "        accion = 3\n",
    "    elif keyboard.is_pressed(\"flecha abajo\"):\n",
    "        accion = 4\n",
    "    elif keyboard.is_pressed(tecla_finalizar):\n",
    "        print(' *** Se presiono finalizar ***')\n",
    "        break\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    # Leer estados del entorno\n",
    "    observation, reward, terminated, truncated, info = env.step(accion)\n",
    "    \n",
    "    reward_global += reward\n",
    "    pasos_ciclo += 1\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    #print('rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "        # Evaluar el reward ganado/perdido por cada intervalo. En caso no se evidencie mejora se finaliza\n",
    "    if(steps_to_finish < pasos_ciclo):\n",
    "        if(reward_global - reward_to_finish < min_reward_to_finish):\n",
    "            finish_simulation = True\n",
    "            \n",
    "        # Actualizar parametros\n",
    "        steps_to_finish += steps_batch\n",
    "        reward_to_finish = reward_global\n",
    "        \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated or finish_simulation:\n",
    "        \n",
    "        # Reset de entorno de simulacion\n",
    "        observation, info = env.reset()\n",
    "        \n",
    "        # tiempo de ciclo\n",
    "        duracion_ciclo = np.round(time.time() - time_start,1)\n",
    "        \n",
    "        # Informativo\n",
    "        print('# ciclo:',num_ciclo,'; completado:',terminated,'; truncado:',truncated,'; # pasos:',pasos_ciclo,'; reward:',np.round(reward_global,3),'; tiempo:',duracion_ciclo,'[sec] <> ',np.round(duracion_ciclo/60.0,2),'[min]')\n",
    "        \n",
    "        # Reiniciar/Actualizar variables\n",
    "        reward_global = 0\n",
    "        time_start = time.time()\n",
    "        pasos_ciclo = 0\n",
    "        num_ciclo += 1\n",
    "        \n",
    "        # Detener simulacion\n",
    "        steps_to_finish = steps_batch\n",
    "        reward_to_finish = 0\n",
    "        finish_simulation = False\n",
    "        \n",
    "        \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b460b66",
   "metadata": {
    "hidden": true
   },
   "source": [
    "3) Simulacion por teclado y generación de video para entrenamiento de Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3721a77e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T15:54:04.465583Z",
     "start_time": "2022-11-16T15:52:18.650013Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Porcentaje a completar: 85.0 %\n",
      "Acciones del espacio: Discrete(5)\n",
      "-------------------------------------\n",
      "[INFO] Presione tecla para finalizar:  s\n",
      "[INICIO] Presione la tecla \"i\" para iniciar\n",
      "Se ha iniciado la simulacion\n",
      "# ciclo: 1 ; completado: False ; truncado: False ; # pasos: 1379 ; reward: 842.428 ; tiempo: 29.2 [sec] <>  0.49 [min]\n",
      "# ciclo: 2 ; completado: False ; truncado: False ; # pasos: 530 ; reward: 337.572 ; tiempo: 11.8 [sec] <>  0.2 [min]\n",
      "# ciclo: 3 ; completado: False ; truncado: True ; # pasos: 955 ; reward: 904.5 ; tiempo: 19.5 [sec] <>  0.32 [min]\n",
      "# ciclo: 4 ; completado: False ; truncado: False ; # pasos: 463 ; reward: 323.953 ; tiempo: 10.5 [sec] <>  0.18 [min]\n",
      "# ciclo: 5 ; completado: False ; truncado: False ; # pasos: 578 ; reward: 508.302 ; tiempo: 12.8 [sec] <>  0.21 [min]\n",
      "# ciclo: 6 ; completado: False ; truncado: False ; # pasos: 870 ; reward: 735.785 ; tiempo: 18.8 [sec] <>  0.31 [min]\n",
      " *** Se presiono finalizar ***\n"
     ]
    }
   ],
   "source": [
    "# [Generar videos] Simulador de Carro con ingreso por teclado & grabar video\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "\n",
    "perc_complete = 0.85\n",
    "gym_env = \"CarRacing-v2\"\n",
    "\n",
    "env = gym.make(gym_env, render_mode=\"human\",\n",
    "               max_episode_steps=10000,\n",
    "               continuous=False,\n",
    "               lap_complete_percent=perc_complete)\n",
    "\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print('Porcentaje a completar:',np.round(100.*perc_complete,1),'%')\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "print('-------------------------------------')\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "#########################################\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Tecla para finalizar\n",
    "tecla_finalizar = \"s\"\n",
    "print('[INFO] Presione tecla para finalizar: ',tecla_finalizar)\n",
    "\n",
    "# Tecla para finalizar ciclo actual\n",
    "tecla_finaliza_ciclo = \"C\"\n",
    "\n",
    "# Informacion de teclados:\n",
    "## DERECHA: ir a la derecha (incluye girar)\n",
    "## IZQUIERDA: ir a la izquierda (incluye girar)\n",
    "## ARRIBA: avanzar aumentando velocidad\n",
    "## ABAJO: Reduce velocidad\n",
    "## TECLA SALIR: \"S\"      (Definido lineas arriba)\n",
    "## TECLA Finaliza ciclo actual: \"C\"   (Definido lineas arriba)\n",
    "\n",
    "# Parametro de finalizacion - en caso se equivoque mucho finalizar ya!!\n",
    "min_reward_to_finish = 12.5\n",
    "steps_batch = 300\n",
    "steps_to_finish = steps_batch\n",
    "reward_to_finish = 0\n",
    "finish_simulation = False\n",
    "\n",
    "#############################\n",
    "\n",
    "print('[INICIO] Presione la tecla \"i\" para iniciar')\n",
    "while(not keyboard.is_pressed(\"i\")):\n",
    "    pass\n",
    "\n",
    "print('Se ha iniciado la simulacion')\n",
    "observation, info = env.reset()\n",
    "\n",
    "#############################\n",
    "\n",
    "# Inicializar parametros\n",
    "time_start = time.time()\n",
    "reward_global = 0\n",
    "pasos_ciclo = 0\n",
    "num_ciclo = 1\n",
    "\n",
    "################################\n",
    "# Variable para guardar video\n",
    "num_simulacion = 1\n",
    "nombre_video = \"simula_\"+ str(num_simulacion) + \"_\" + str(num_ciclo) +\".mp4\"\n",
    "frame_size = env.observation_space.shape[:2]\n",
    "fps = 60\n",
    "\n",
    "# Inicio grabacion video\n",
    "result_video = cv2.VideoWriter(nombre_video, cv2.VideoWriter_fourcc(*'MP4V'),fps, frame_size)\n",
    "#################################\n",
    "\n",
    "# Simulacion\n",
    "while True:\n",
    "    \n",
    "    # Accion por defecto en caso no se presione nada\n",
    "    accion = 0\n",
    "    \n",
    "    # En caso se presione alguna tecla en especifico\n",
    "    if keyboard.is_pressed(\"flecha derecha\"):\n",
    "        accion = 1\n",
    "    elif keyboard.is_pressed(\"flecha izquierda\"):\n",
    "        accion = 2\n",
    "    elif keyboard.is_pressed(\"flecha arriba\"):\n",
    "        accion = 3\n",
    "    elif keyboard.is_pressed(\"flecha abajo\"):\n",
    "        accion = 4\n",
    "    elif keyboard.is_pressed(tecla_finaliza_ciclo):\n",
    "        finish_simulation = True\n",
    "        time.sleep(1) # esperar 1 segundo\n",
    "    elif keyboard.is_pressed(tecla_finalizar):\n",
    "        print(' *** Se presiono finalizar ***')\n",
    "        try:\n",
    "            # finaliza video\n",
    "            result_video.release()\n",
    "        except:\n",
    "            pass\n",
    "        # finalizar bucle while\n",
    "        break\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    # Leer estados del entorno\n",
    "    observation, reward, terminated, truncated, info = env.step(accion)\n",
    "    \n",
    "    reward_global += reward\n",
    "    pasos_ciclo += 1\n",
    "    \n",
    "    # Guadar imagen a video\n",
    "    result_video.write(observation[:,:,::-1])\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    #print('rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "        # Evaluar el reward ganado/perdido por cada intervalo. En caso no se evidencie mejora se finaliza\n",
    "    if(steps_to_finish < pasos_ciclo):\n",
    "        if(reward_global - reward_to_finish < min_reward_to_finish):\n",
    "            finish_simulation = True\n",
    "            \n",
    "        # Actualizar parametros\n",
    "        steps_to_finish += steps_batch\n",
    "        reward_to_finish = reward_global\n",
    "        \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated or finish_simulation:\n",
    "        \n",
    "        # Reset de entorno de simulacion\n",
    "        observation, info = env.reset()\n",
    "        \n",
    "        # tiempo de ciclo\n",
    "        duracion_ciclo = np.round(time.time() - time_start,1)\n",
    "        \n",
    "        # Informativo\n",
    "        print('# ciclo:',num_ciclo,'; completado:',terminated,'; truncado:',truncated,'; # pasos:',pasos_ciclo,'; reward:',np.round(reward_global,3),'; tiempo:',duracion_ciclo,'[sec] <> ',np.round(duracion_ciclo/60.0,2),'[min]')\n",
    "        \n",
    "        # Finaliza video\n",
    "        result_video.release()\n",
    "\n",
    "        # Reiniciar/Actualizar variables\n",
    "        reward_global = 0\n",
    "        time_start = time.time()\n",
    "        pasos_ciclo = 0\n",
    "        num_ciclo += 1\n",
    "        \n",
    "        # Detener simulacion\n",
    "        steps_to_finish = steps_batch\n",
    "        reward_to_finish = 0\n",
    "        finish_simulation = False\n",
    "        \n",
    "        # Inicializar video - empieza a grabar nuevo archivo\n",
    "        nombre_video = \"simula_\"+ str(num_simulacion) + \"_\" + str(num_ciclo) +\".mp4\"\n",
    "        result_video = cv2.VideoWriter(nombre_video, cv2.VideoWriter_fourcc(*'MP4V'),fps, frame_size)\n",
    "        \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de37c927",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Reinforcement Learning - Aplicación Q-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733a5d6",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Caso 1- Tabla 4x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d10f9d91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T04:59:47.149615Z",
     "start_time": "2022-11-29T04:59:40.720100Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Tabla inicial:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "\n",
      "===========================================\n",
      "Q-Tabla final:\n",
      "[[266.251941   295.83549    295.83549    266.251941  ]\n",
      " [266.251941     0.         328.7061     295.83549   ]\n",
      " [295.83549    365.229      295.83549    328.7061    ]\n",
      " [328.7061       0.         295.83410891 295.04338045]\n",
      " [295.83548998 328.7061       0.         266.251941  ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.         405.81         0.         328.7061    ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [328.70599953   0.         365.229      295.83548999]\n",
      " [328.70609892 405.80999893 405.81         0.        ]\n",
      " [365.229      450.9          0.         365.229     ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.           0.           0.           0.        ]\n",
      " [  0.         353.93652669 450.9        364.69383617]\n",
      " [405.81       450.9        501.         405.81      ]\n",
      " [  0.           0.           0.           0.        ]]\n",
      "Cantidad exito: 29552  de  30000 ; Ratio de exito= 98.507 %\n"
     ]
    }
   ],
   "source": [
    "# Caso 1 - tabla 4x4\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "environment = gym.make(\"FrozenLake-v1\", is_slippery=False,map_name=\"4x4\")\n",
    "environment.reset()\n",
    "environment.render()\n",
    "\n",
    "nb_states = environment.observation_space.n\n",
    "nb_actions = environment.action_space.n \n",
    "qtable = np.zeros((nb_states, nb_actions))\n",
    "\n",
    "# Artificio de agregar un valor diferente de cero inicial\n",
    "qtable = qtable + 0.0  \n",
    "\n",
    "\n",
    "# Hiperparametros\n",
    "episodes = 30000        # numero episodios\n",
    "alpha = 0.5            # Learning rate\n",
    "gamma = 0.9            # Discount factor\n",
    "epsilon = 0.90          # Amount of randomness in the action selection\n",
    "epsilon_decay = 0.001  # Fixed amount to decrease\n",
    "max_ii = 50            # limite de pasos por episodio\n",
    "\n",
    "print('Q-Tabla inicial:')\n",
    "print(qtable)\n",
    "\n",
    "# Llevar conteo de casos de exito\n",
    "cantidad_exitos = 0\n",
    "\n",
    "# guardar casos de exito\n",
    "camino_exitoso = []\n",
    "\n",
    "# Entrenamiento\n",
    "for ii in range(episodes):\n",
    "    \n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # camino seguido en episodio \n",
    "    camino_episodio_actual = []\n",
    "    \n",
    "    # tabla previa\n",
    "    qtable_anterior = qtable.copy()\n",
    "    \n",
    "    # flag para indicar si tuvo o no exito en episodio actual\n",
    "    exito_actual = 0\n",
    "    \n",
    "    # entrenar y actualizar matriz Q\n",
    "    while not done:\n",
    "        \n",
    "        # valor aleatorio entre 0 y 1\n",
    "        rnd = np.random.random()\n",
    "\n",
    "        # si se cumple rnd < epsilon tomar una accion aleatoria\n",
    "        if rnd < epsilon:\n",
    "            action = environment.action_space.sample()\n",
    "            \n",
    "        # si no es aleatorio, seleccionar la opcion con Q mas alto\n",
    "        else:\n",
    "            # Opcion 1\n",
    "            #action = np.argmax(qtable[state])\n",
    "            \n",
    "            # Opcion 2\n",
    "            vector = qtable[state]\n",
    "            action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "             \n",
    "        # aplicar accion\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        # guardar camino\n",
    "        camino_episodio_actual.append((state,action,new_state))\n",
    "        \n",
    "        # En caso de no llegar a recomensa\n",
    "        if reward < 1:\n",
    "            reward = reward - 0.0\n",
    "        \n",
    "        # En caso de recompensa\n",
    "        if reward >= 1:\n",
    "            reward = reward + 500\n",
    "        \n",
    "        # Actualiza el valor de Q(s,a) segun accion y estado\n",
    "        qtable[state, action] = qtable[state, action] + \\\n",
    "                                alpha * (reward + gamma * np.max(qtable[new_state]) - qtable[state, action])\n",
    "        \n",
    "        # actualiza estado actual\n",
    "        state = new_state\n",
    "        \n",
    "        # Se ganó la busqueda del objetivo principal\n",
    "        if reward >= 1:\n",
    "            cantidad_exitos += 1\n",
    "            camino_exitoso.append(camino_episodio_actual) # agregar camino de episodio actual a caso de exito\n",
    "            exito_actual = 1\n",
    "            #print('Exito en episodio:',ii,'; pasos:',pasos_ii,'; estado:',state,'; reward:',reward)\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        \n",
    "        # En caso se exceda de la cantidad maximas de pasos en un episodio salir de bucle\n",
    "        if(pasos_ii > max_ii):\n",
    "            qtable = qtable_anterior.copy()\n",
    "            break\n",
    "    \n",
    "    ########################\n",
    "    #### fin episodio  #####\n",
    "    \n",
    "    # Actualizar epsilon\n",
    "    epsilon = max(epsilon - epsilon_decay, 0)\n",
    "    \n",
    "    # Actualizar valor de tabla anterior\n",
    "    qtable_anterior = qtable.copy()\n",
    "\n",
    "print()\n",
    "print('===========================================')\n",
    "print('Q-Tabla final:')\n",
    "print(qtable)\n",
    "\n",
    "print (\"Cantidad exito:\",cantidad_exitos,\" de \",episodes,\"; Ratio de exito=\",np.round(100.*(cantidad_exitos/episodes),3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4e9994d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T04:59:47.165661Z",
     "start_time": "2022-11-29T04:59:47.151558Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29552"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de caminos exitosos\n",
    "len(camino_exitoso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8f476b2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T04:59:47.181663Z",
     "start_time": "2022-11-29T04:59:47.167660Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tupla se lee: (state_actual, action, new_state)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 1, 4), (4, 1, 8), (8, 2, 9), (9, 2, 10), (10, 1, 14), (14, 2, 15)]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver cada camino seguido\n",
    "\n",
    "# cada tupla se lee: (state_actual, action, new_state)\n",
    "i = -1\n",
    "print('La tupla se lee: (state_actual, action, new_state)')\n",
    "camino_exitoso[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c3da8d75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T04:59:49.379656Z",
     "start_time": "2022-11-29T04:59:49.356450Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 1 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 2 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 3 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 4 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 5 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 6 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 7 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 8 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 9 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 10 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 11 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 12 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 13 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 14 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 15 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 16 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 17 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 18 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 19 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 20 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 21 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 22 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 23 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 24 ; num pasos: 5 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Casos exito: 25.0 ; Ratio de exito= 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Aplicar a \"Q\" entrenado\n",
    "\n",
    "# Cantidad de simulaciones\n",
    "episodes = 25\n",
    "\n",
    "# Registro de simulaciones exitosas\n",
    "nb_success = 0\n",
    "\n",
    " # limite de pasos por episodio\n",
    "max_ii = 100\n",
    "\n",
    "# Evaluacion\n",
    "for ii in range(episodes):\n",
    "\n",
    "    # Inicializar entorno\n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # Hasta que finalice o se atore\n",
    "    while not done:\n",
    "        \n",
    "        # Opcion 1\n",
    "        #action = np.argmax(qtable[state])\n",
    "\n",
    "        # Opcion 2\n",
    "        vector = qtable[state]\n",
    "        action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "\n",
    "        # Aplicar accion y ver nuevos estados\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        #print('Estado:',new_state,'; Recompensa:',reward,'; Finalizacion:',done)\n",
    "        \n",
    "        # Actualizar estado\n",
    "        state = new_state\n",
    "        \n",
    "        # information\n",
    "        #print('Episode:',ii,'; num pasos:',pasos_ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "        \n",
    "        # Si se da recomensa, se ganó el juego\n",
    "        if reward >= 1:\n",
    "            nb_success += reward\n",
    "            print('Episode:',ii,'; num pasos:',pasos_ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "            break\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        if(pasos_ii > max_ii):\n",
    "            break\n",
    "\n",
    "print (\"Casos exito:\",nb_success,\"; Ratio de exito=\",np.round(100.*(nb_success/episodes),1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f215acd3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Para el caso de un tablero 4x4 se ve que se logró aprender la matriz Q para la deteminación de la \"acción\" segun el estado. Por lo que el objeto es capaz de navegar hacia la busqueda de la mayor recompensa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77374a3e",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Caso 2 - tabla 8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4a9a92f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T05:00:25.429739Z",
     "start_time": "2022-11-29T05:00:01.052759Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Tabla inicial:\n",
      "[[0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]]\n",
      "\n",
      "===========================================\n",
      "Q-Tabla final:\n",
      "[[0.00000000e+00 0.00000000e+00 2.57184383e+02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.70720404e+02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.84968846e+02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 2.99967207e+02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.15754954e+02 0.00000000e+00]\n",
      " [0.00000000e+00 3.32373636e+02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.99967207e-31]\n",
      " [0.00000000e+00 0.00000000e+00 3.49866985e+02 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 3.68281037e+02 0.00000000e+00]\n",
      " [0.00000000e+00 3.87664250e+02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.08067631e+02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.29544875e+02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.52152500e+02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 4.75950000e+02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 5.01000000e+02 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "Cantidad exito: 48661  de  50000 ; Ratio de exito= 97.322 %\n"
     ]
    }
   ],
   "source": [
    "# Caso 2 - tabla 8x8\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "environment = gym.make(\"FrozenLake-v1\", is_slippery=False,map_name=\"8x8\")\n",
    "environment.reset()\n",
    "environment.render()\n",
    "\n",
    "nb_states = environment.observation_space.n\n",
    "nb_actions = environment.action_space.n \n",
    "qtable = np.zeros((nb_states, nb_actions))\n",
    "\n",
    "# Artificio de agregar un valor diferente de cero inicial\n",
    "qtable = qtable + 0.0  \n",
    "\n",
    "\n",
    "# Hiperparametros\n",
    "episodes = 50000        # numero episodios\n",
    "alpha = 0.001            # Learning rate\n",
    "gamma = 0.95           # Discount factor\n",
    "epsilon = 1.0          # Amount of randomness in the action selection\n",
    "epsilon_decay = 0.02   # Fixed amount to decrease\n",
    "max_ii = 150            # limite de pasos por episodio\n",
    "\n",
    "print('Q-Tabla inicial:')\n",
    "print(qtable)\n",
    "\n",
    "# Llevar conteo de casos de exito\n",
    "cantidad_exitos = 0\n",
    "\n",
    "# guardar casos de exito\n",
    "camino_exitoso = []\n",
    "\n",
    "# Entrenamiento\n",
    "for ii in range(episodes):\n",
    "    \n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # camino seguido en episodio \n",
    "    camino_episodio_actual = []\n",
    "    \n",
    "    # tabla previa\n",
    "    qtable_anterior = qtable.copy()\n",
    "    \n",
    "    # flag para indicar si tuvo o no exito en episodio actual\n",
    "    exito_actual = 0\n",
    "    \n",
    "    # entrenar y actualizar matriz Q\n",
    "    while not done:\n",
    "        \n",
    "        # valor aleatorio entre 0 y 1\n",
    "        rnd = np.random.random()\n",
    "\n",
    "        # si se cumple rnd < epsilon tomar una accion aleatoria\n",
    "        if rnd < epsilon:\n",
    "            action = environment.action_space.sample()\n",
    "            \n",
    "        # si no es aleatorio, seleccionar la opcion con Q mas alto\n",
    "        else:\n",
    "            # Opcion 1\n",
    "            #action = np.argmax(qtable[state])\n",
    "            \n",
    "            # Opcion 2\n",
    "            vector = qtable[state]\n",
    "            action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "             \n",
    "        # aplicar accion\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        # guardar camino\n",
    "        camino_episodio_actual.append((state,action,new_state))\n",
    "        \n",
    "        # En caso de no llegar a recomensa\n",
    "        if reward < 1:\n",
    "            reward = reward - 0.0\n",
    "        \n",
    "        # En caso de recompensa\n",
    "        if reward >= 1:\n",
    "            reward = reward + 500\n",
    "        \n",
    "        # Actualiza el valor de Q(s,a) segun accion y estado\n",
    "        qtable[state, action] = qtable[state, action] + \\\n",
    "                                alpha * (reward + gamma * np.max(qtable[new_state]) - qtable[state, action])\n",
    "        \n",
    "        # actualiza estado actual\n",
    "        state = new_state\n",
    "        \n",
    "        # Se ganó la busqueda del objetivo principal\n",
    "        if reward >= 1:\n",
    "            cantidad_exitos += 1\n",
    "            camino_exitoso.append(camino_episodio_actual) # agregar camino de episodio actual a caso de exito\n",
    "            exito_actual = 1\n",
    "            #print('Exito en episodio:',ii,'; pasos:',pasos_ii,'; estado:',state,'; reward:',reward)\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        \n",
    "        # En caso se exceda de la cantidad maximas de pasos en un episodio salir de bucle\n",
    "        if(pasos_ii > max_ii):\n",
    "            qtable = qtable_anterior.copy()\n",
    "            break\n",
    "    \n",
    "    ########################\n",
    "    #### fin episodio  #####\n",
    "    \n",
    "    # Actualizar epsilon\n",
    "    epsilon = max(epsilon - epsilon_decay, 0)\n",
    "    \n",
    "    # Actualizar valor de tabla anterior\n",
    "    qtable_anterior = qtable.copy()\n",
    "\n",
    "print()\n",
    "print('===========================================')\n",
    "print('Q-Tabla final:')\n",
    "print(qtable)\n",
    "\n",
    "print (\"Cantidad exito:\",cantidad_exitos,\" de \",episodes,\"; Ratio de exito=\",np.round(100.*(cantidad_exitos/episodes),3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f6b9f1ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T05:00:25.445692Z",
     "start_time": "2022-11-29T05:00:25.431753Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48661"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de caminos exitosos\n",
    "len(camino_exitoso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6f06f373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T05:00:25.461691Z",
     "start_time": "2022-11-29T05:00:25.446692Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La tupla se lee: (state_actual, action, new_state)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0, 2, 1),\n",
       " (1, 2, 2),\n",
       " (2, 2, 3),\n",
       " (3, 2, 4),\n",
       " (4, 2, 5),\n",
       " (5, 1, 13),\n",
       " (13, 2, 14),\n",
       " (14, 2, 15),\n",
       " (15, 1, 23),\n",
       " (23, 1, 31),\n",
       " (31, 1, 39),\n",
       " (39, 1, 47),\n",
       " (47, 1, 55),\n",
       " (55, 1, 63)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver cada camino seguido\n",
    "\n",
    "# cada tupla se lee: (state_actual, action, new_state)\n",
    "i = -1\n",
    "\n",
    "print('La tupla se lee: (state_actual, action, new_state)')\n",
    "camino_exitoso[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "cc3d2e5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-29T05:00:25.493173Z",
     "start_time": "2022-11-29T05:00:25.463691Z"
    },
    "code_folding": [
     0
    ],
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 1 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 2 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 3 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 4 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 5 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 6 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 7 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 8 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 9 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 10 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 11 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 12 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 13 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 14 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 15 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 16 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 17 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 18 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 19 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 20 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 21 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 22 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 23 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Episode: 24 ; num pasos: 13 ; action: 1 ; state: 63 ; reward: 1.0\n",
      "Casos exito: 25.0 ; Ratio de exito= 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Aplicar a \"Q\" entrenado\n",
    "\n",
    "# Cantidad de simulaciones\n",
    "episodes = 25\n",
    "\n",
    "# Registro de simulaciones exitosas\n",
    "nb_success = 0\n",
    "\n",
    " # limite de pasos por episodio\n",
    "max_ii = 100\n",
    "\n",
    "# Evaluacion\n",
    "for ii in range(episodes):\n",
    "\n",
    "    # Inicializar entorno\n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # Hasta que finalice o se atore\n",
    "    while not done:\n",
    "        \n",
    "        # Opcion 1\n",
    "        #action = np.argmax(qtable[state])\n",
    "\n",
    "        # Opcion 2\n",
    "        vector = qtable[state]\n",
    "        action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "\n",
    "        # Aplicar accion y ver nuevos estados\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        #print('Estado:',new_state,'; Recompensa:',reward,'; Finalizacion:',done)\n",
    "        \n",
    "        # Actualizar estado\n",
    "        state = new_state\n",
    "        \n",
    "        # information\n",
    "        #print('Episode:',ii,'; num pasos:',pasos_ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "        \n",
    "        # Si se da recomensa, se ganó el juego\n",
    "        if reward >= 1:\n",
    "            nb_success += reward\n",
    "            print('Episode:',ii,'; num pasos:',pasos_ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "            break\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        if(pasos_ii > max_ii):\n",
    "            break\n",
    "\n",
    "print (\"Casos exito:\",nb_success,\"; Ratio de exito=\",np.round(100.*(nb_success/episodes),1),\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
