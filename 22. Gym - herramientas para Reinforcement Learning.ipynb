{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd6801b3",
   "metadata": {},
   "source": [
    "El objetivo de este notebook es el brindar ejemplos de acceso y uso de ambientes para simulación orientados al Reinforcement Learning (Aprendizaje por reforzamiento) mediante la libreria Gym. Link con documentacion: https://www.gymlibrary.dev/content/basic_usage/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ac9bde74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:13:27.667451Z",
     "start_time": "2022-11-28T03:13:27.654539Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Librerias\n",
    "\n",
    "import gym\n",
    "import keyboard\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572f0ec9",
   "metadata": {},
   "source": [
    "## Simulador GymAI > Ambientes diversos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf115f4",
   "metadata": {},
   "source": [
    "Escenario: LunarLander-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6f0426c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:07:27.333502Z",
     "start_time": "2022-11-28T03:07:23.407370Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: LunarLander-v2\n",
      "Acciones del espacio: Discrete(4)\n",
      "muestra ::  0\n",
      "muestra ::  3\n",
      "muestra ::  2\n",
      "muestra ::  1\n",
      "muestra ::  1\n",
      "muestra ::  3\n",
      "muestra ::  0\n",
      "muestra ::  2\n",
      "muestra ::  0\n",
      "muestra ::  0\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: -2.497033478022092 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: 0.3028158191380623 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -4.084324611699333 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.06415158466822277 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -4.230430849374488 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: 0.012746637376268383 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -2.8209334305346827 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: 0.44435753911477605 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.34957934879241637 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: 1.1449635758303611 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -2.2152398545693925 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: 1.199374137458393 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: 0.5782678686134091 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: -0.39931580881619655 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: -1.0205897198816831 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -2.729823545860671 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: 0.973169224956963 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.8272269772758125 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: -4.934150697483164 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 0.6306953972599001 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: 0.8484956601110138 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.10775034724173338 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.30228160250740643 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -3.8740962831673924 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -1.5181619457291322 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: -0.7609956752394851 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: -2.1027271739572755 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: -2.478108164921507 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.3946844182438827 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -1.5072828837337966 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -1.6521914239254443 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -3.1332412960061604 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -2.4452637053411364 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: -0.6616309017342974 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -1.8649748393497987 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: -3.095805060199693 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: -1.1563142141057756 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: -3.3463245673891877 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: -1.9385396426059913 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -3.505726530843218 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: -3.4463851406184163 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -2.7413437001413 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -1.8424036798431007 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: -1.8571298325692271 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: -1.5972672490282196 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: -2.317262857843957 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: -3.103316515477604 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: -2.1731876155705834 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: -2.05800974868298 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: -3.0253473947238545 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 1 - de ambiente simulacion\n",
    "\n",
    "gym_env = \"LunarLander-v2\"\n",
    "env = gym.make(gym_env, render_mode=\"human\")\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "    \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7828ddd",
   "metadata": {},
   "source": [
    "Escenario: CartPole-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86c8515c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:07:38.322030Z",
     "start_time": "2022-11-28T03:07:36.248554Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CartPole-v1\n",
      "Acciones del espacio: Discrete(2)\n",
      "muestra ::  0\n",
      "muestra ::  1\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "muestra ::  0\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "muestra ::  0\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: 1.0 ;term: True ;trun: False ;info: {}\n",
      "------- Finalizado (Consiguió objetivo) ---------------\n",
      "i: 11 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: 1.0 ;term: True ;trun: False ;info: {}\n",
      "------- Finalizado (Consiguió objetivo) ---------------\n",
      "i: 47 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: 1.0 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 2 - de ambiente simulacion\n",
    "\n",
    "gym_env = \"CartPole-v1\"\n",
    "env = gym.make(gym_env, render_mode=\"human\")\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "\n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4639c9",
   "metadata": {},
   "source": [
    "Escenario: BipedalWalker-v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fdbf029",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:07:48.152005Z",
     "start_time": "2022-11-28T03:07:46.115744Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: BipedalWalker-v3\n",
      "Acciones del espacio: Box(-1.0, 1.0, (4,), float32)\n",
      "muestra ::  [ 0.5479121  -0.12224312  0.71719587  0.39473605]\n",
      "muestra ::  [-0.8116453  0.9512447  0.5222794  0.5721286]\n",
      "muestra ::  [-0.74377275 -0.09922812 -0.25840396  0.85353   ]\n",
      "muestra ::  [ 0.28773025  0.64552325 -0.1131716  -0.5455226 ]\n",
      "muestra ::  [ 0.10916957 -0.8723655   0.65526235  0.2633288 ]\n",
      "muestra ::  [ 0.5161755  -0.29094806  0.94139606  0.78624225]\n",
      "muestra ::  [ 0.556767  -0.6107226 -0.066558  -0.9123925]\n",
      "muestra ::  [-0.69142103  0.3660979   0.4895243   0.9350195 ]\n",
      "muestra ::  [-0.34834927 -0.2590806  -0.06088838 -0.6210573 ]\n",
      "muestra ::  [-0.740157   -0.04859015 -0.5461813   0.33962798]\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: -0.03677048385639867 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: -0.12128347212386865 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -0.12639417488376062 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.18618398785591125 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -0.1334285677472762 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: -0.12666408969958506 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -0.17000708866119382 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: -0.024435176074504857 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.033851756831012554 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: 0.05692235102256376 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -0.09035675211747723 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: -0.046714869966108415 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: 0.05029917001289508 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: 0.06583368244767189 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: 0.03515792099634925 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -0.013376621777813822 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: -0.048433364883065225 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.008062145233154296 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: 0.03817116846392672 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 0.022094737824052572 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: 0.0020779402529188078 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.1674081994270273 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.14762182070811472 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -0.09895633501807967 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -0.006356225719053359 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: 0.06988523552566767 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: 0.045934727206826204 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: 0.042538841515779496 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.047774908423423766 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -0.026592801779508592 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -0.21871826105316716 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -0.11595947506030282 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -0.11892899042616405 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: -0.13629220004876336 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -0.056696600099403464 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: 0.009465642149247345 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: 0.032888669649761115 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: 0.08048467103640358 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: 0.002112373590469358 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -0.005413786649703978 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: 0.0285516682288908 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -0.0633392872015647 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -0.010249168938644346 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: 0.07046689116954803 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: 0.11549892012278003 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: 0.12938673095902042 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: 0.16951408779621124 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: 0.16054574155807494 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: 0.22392252137263494 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: 0.16408513531088828 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 3 - de ambiente simulacion\n",
    "\n",
    "gym_env = \"BipedalWalker-v3\"\n",
    "env = gym.make(gym_env, render_mode=\"human\")\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "\n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df69b124",
   "metadata": {},
   "source": [
    "## Simulador GymAI > Box2D > Car Racing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478cc9e6",
   "metadata": {},
   "source": [
    "Caso de accion \"continua\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ece7103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:08:02.484932Z",
     "start_time": "2022-11-28T03:08:00.207194Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Acciones del espacio: Box([-1.  0.  0.], 1.0, (3,), float32)\n",
      "muestra ::  [0.5479121  0.43887845 0.85859793]\n",
      "muestra ::  [0.39473605 0.09417735 0.97562236]\n",
      "muestra ::  [0.5222794  0.7860643  0.12811363]\n",
      "muestra ::  [-0.09922812  0.37079802  0.92676497]\n",
      "muestra ::  [0.28773025 0.8227616  0.4434142 ]\n",
      "muestra ::  [-0.5455226   0.5545848   0.06381726]\n",
      "muestra ::  [0.65526235 0.6316644  0.75808775]\n",
      "muestra ::  [-0.29094806  0.970698    0.8931211 ]\n",
      "muestra ::  [0.556767   0.19463871 0.466721  ]\n",
      "muestra ::  [-0.9123925   0.1542895   0.68304896]\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: 6.967137809187279 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: 3.4335689045936393 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 4 (opcion continua) - de ambiente simulacion de carros\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "gym_env = \"CarRacing-v2\"\n",
    "env = gym.make(gym_env, render_mode=\"human\",continuous=True,lap_complete_percent=1.00)\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "    \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6c5e1a",
   "metadata": {},
   "source": [
    "Caso de accion \"discreta\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2b8987",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:08:11.094248Z",
     "start_time": "2022-11-28T03:08:08.763953Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Acciones del espacio: Discrete(5)\n",
      "muestra ::  0\n",
      "muestra ::  3\n",
      "muestra ::  3\n",
      "muestra ::  2\n",
      "muestra ::  2\n",
      "muestra ::  4\n",
      "muestra ::  0\n",
      "muestra ::  3\n",
      "muestra ::  1\n",
      "muestra ::  0\n",
      "..............................\n",
      "Numero pasos: 50\n",
      "..............................\n",
      "i: 0 ;rew: 6.967137809187279 ;term: False ;trun: False ;info: {}\n",
      "i: 1 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 2 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 3 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 4 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 5 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 6 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 7 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 8 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 9 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 10 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 11 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 12 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 13 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 14 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 15 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 16 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 17 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 18 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 19 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 20 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 21 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 22 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 23 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 24 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 25 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 26 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 27 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 28 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 29 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 30 ;rew: -0.10000000000000009 ;term: False ;trun: False ;info: {}\n",
      "i: 31 ;rew: -0.10000000000000009 ;term: False ;trun: False ;info: {}\n",
      "i: 32 ;rew: -0.10000000000000009 ;term: False ;trun: False ;info: {}\n",
      "i: 33 ;rew: 3.4335689045936397 ;term: False ;trun: False ;info: {}\n",
      "i: 34 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 35 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 36 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 37 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 38 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 39 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 40 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 41 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 42 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 43 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 44 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 45 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 46 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 47 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 48 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n",
      "i: 49 ;rew: -0.09999999999999964 ;term: False ;trun: False ;info: {}\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo 4 (opcion discreta) - de ambiente simulacion de carros\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "gym_env = \"CarRacing-v2\"\n",
    "env = gym.make(gym_env, render_mode=\"human\",continuous=False,lap_complete_percent=1.00)\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Ver ejemplos de input\n",
    "for i in range(10):\n",
    "    print('muestra :: ',env.action_space.sample())\n",
    "\n",
    "print('..............................')\n",
    "n_pasos = 50\n",
    "print('Numero pasos:',n_pasos)\n",
    "print('..............................')\n",
    "\n",
    "# Recorrer los n_pasos\n",
    "for i in range(n_pasos):\n",
    "    \n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('i:',i,';obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    print('i:',i,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated:\n",
    "        observation, info = env.reset()\n",
    "        print('------- Finalizado (Consiguió objetivo) ---------------')\n",
    "    \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d8e763f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:08:29.085499Z",
     "start_time": "2022-11-28T03:08:28.962160Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAq4AAAKsCAYAAAAtNz8NAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAinUlEQVR4nO3db6xtd1kn8O+v5957bltK/1DoYNsZQFAHGR1MA2iJQXASRon0BTBMHKcxEN44459IHPANmcTJaCIqMWjSgKaTkAFTUZjBOFGEDLyQcBESRsqMplpoc5GiLb0C9/z9zYuzDQXvWvecfffeaz/nfD7JTe9ez1lrPbdde53v/XXt57TeewAAYN1dNXUDAABwGIIrAAAlCK4AAJQguAIAUILgCgBACYIrAAAlnLqSnVtrL0/ytiQbSd7Re//Fsa8/e9PZft3t113JKTnO9kdquyvrgnW1N1J7dGVdUNHYd7obVtUEcFgXzl/IxccutkvV5g6urbWNJG9P8q+SPJTk46219/fePzO0z3W3X5e7/uCueU/JcffVkdpjq2qCtfXlkdp7VtYFFT1tpHbXqpoADuv3//3vD9au5FGBFyT5y977A7337STvTvLKKzgeAAAMupLgemuSzz/h9UOzbQAAsHBL/3BWa+0NrbVzrbVzF//24rJPBwDAMXUlwfXhJLc/4fVts23foPd+T+/9jt77HWefcvYKTgcAwEl2JcH140me01p7ZmvtTJLXJnn/YtoCAIBvNPdUgd77bmvtPyT5XzkYh/Vbvfc/X1hnnDzbUzfAOms7l5yMMisu9ly998UekGmdnroBYFGuaI5r7/0PkvzBgnoBAIBBfnIWAAAlCK4AAJQguAIAUILgCgBACYIrAAAlXNFUAViorakbYJ21/eGZVxunNlbYybBFj9Faxliude9xKaPINhd/SGAaVlwBAChBcAUAoATBFQCAEgRXAABKEFwBACjBVAFWa3ektreyLqhoe+oGLq+14ckH63C8k6pvDk8q2B29KQHrxoorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJRgHBarVWCkEWtqf+oGKOv01A0Ai2LFFQCAEgRXAABKEFwBAChBcAUAoATBFQCAEgRXAABKMA6L1dqaugHKcu0wp36qT90CsCBWXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKEFwBQCgBOOwWC0jjZiXiUbMy3c6ODasuAIAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACYaEsHg7I7X9lXXBMdO229QtUNXpqRsAFsWKKwAAJQiuAACUILgCAFCC4AoAQAmCKwAAJZgqwOJtTd0Ax9LecKn3PlhrzTSCE88SDRwb3s4AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUIJxWCze9tQNcBz17eGRV31/uLZKFUZvrUuPq+yjb67H9QFcOSuuAACUILgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCCcVgsnnFYLMPO1A1cXu/rP3apQo+L1k+N/JnHpnKdvH9VsPasuAIAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACcZhMb+hsVf7K+2Ck2Jv6gYo62lz1r56xO2J6xSWzIorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJRgHBbz25q6AU4U1xvz2pizdt0RtyfJxZHa2Bitseu7j9TghLHiCgBACYIrAAAlCK4AAJQguAIAUILgCgBACaYKMD+f8maVfLKaeZ1Z4bnOzlnbG6kNTSMYm1IwdjwozIorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJRgHBbjxkYQ7aysCzB+jfmtchzWvDZGatcdcXuSXBypPT5S2x2pwRqw4goAQAmCKwAAJQiuAACUILgCAFCC4AoAQAmCKwAAJRiHxbjtkdrYqCxYsL43csHNcS221uZvhlrGRk0dV2dHamPjsGDNWXEFAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBKMw2Lc1tQNwIG+tdhxWL2v/zy3kziyaxl/5n52/f9bL9zenDVYc1ZcAQAoQXAFAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAE47AYZxwW6+IEjvCpMLJr0eb+M49N0TqJSzTbI7WTd1lxjJzEtzMAAAUJrgAAlCC4AgBQguAKAEAJgisAACWYKkCyP1LbXVkXMM61yJix72anV9bF+jARhmPKiisAACUIrgAAlCC4AgBQguAKAEAJgisAACUIrgAAlGAcFsn2SK2vrAsYtzN1A6y1NmftuDIOi2PKiisAACUIrgAAlCC4AgBQguAKAEAJgisAACUIrgAAlHDZcVittduT/Lckt+RgONI9vfe3tdZuSvKeJM9I8tdJXtN7f3T0YLtJhr7impH9Ni/XJVfE2BTWxdj4NaPZGHMSv0/szVmDwg6z4rqb5Gd7789N8qIkP9Fae26SNyX5YO/9OUk+OHsNAABLcdng2ns/33v/s9nvLyS5P8mtSV6Z5N7Zl92b5K4l9QgAAEd7xrW19owkz0/ysSS39N7Pz0pfyMGjBAAAsBSHDq6ttScl+d0kP917f/yJtd57z8ATaK21N7TWzrXWzl189OIVNQsAwMl1qODaWjudg9D6rt77e2eb/6a19vRZ/elJvnipfXvv9/Te7+i933H2xrOL6BkAgBPossG1tdaSvDPJ/b33X3lC6f1J7p79/u4k71t8ewAAcOCy47CS3Jnkx5J8urX2qdm2n0/yi0l+p7X2uiQPJnnNZY+0n+RrA7Wh7WNdjo3QGquZXvuNjMNiXeyM1Iz3YczpqRuYgHs3J9Blg2vv/aNJ2kD5ZYttBwAALs3aIwAAJQiuAACUILgCAFCC4AoAQAmCKwAAJRxmHNb0dge2Pz6wPUkujNTGfg7CtSO1MyO1dTc2SsiYIdZE60MDTJKNUxsLPdfBD/xb3X6rOt66nW9ljMOCE8GKKwAAJQiuAACUILgCAFCC4AoAQAmCKwAAJdSYKjCPsQ/Ofm3O2tCnVq8Z2WesNvwB6sUb+/TpMf2QMQVtD5daW+wbZtHHO86WMYlgnmOO7jMyLWY/+0c+Vwkj7xc4rqy4AgBQguAKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJx3cc1jLsDGz/8sg+j4/Urh6pXTtSGxrLNcbYFCo4plOLqlvG6LBFH7OfHh6VVX4c1u7A9r2VdgGLN7R8OnJ7sOIKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJgisAACUYh7VswxNakq/OWTszsP2akX22RmqwJtr24scucUKcnbqBJXL/5rjaHNhuHBYAANUJrgAAlCC4AgBQguAKAEAJgisAACUIrgAAlGAcVkXbR9wOVexN3QBlbUzdwBIZh8VxNTQOa2RZ1YorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJRgHBawPnanboCyzk7dwBIZdchxdWZgexvexYorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlmCoArA+fnmZOfaNP3cKV2Rmp7a+sC1i8jZHaUAo1VQAAgOoEVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAASjAOC1gbfW94pNH+/nrMBGptZE7LmqjQ48JtTt3AFdqaugFYkgW/N624AgBQguAKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJxmEB62N7uNT78KisVVqXPtbFuoze6qeK/3cxDovjyjgsAABOIsEVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASjMMC1sf+1A1wVOsyHqzEOKyxFkdGwUFpZxZ7OCuuAACUILgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCCcVjA2mi7beoWqGrBI3eWYmekVmCaF4waSpQbiz2NFVcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEowVQBYHwv+9CknSIVrZ2vqBmCJNldzGiuuAACUILgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCCcVjAao3ddXZX1gXHzdVTN3AI21M3AEtkHBYAAHyd4AoAQAmCKwAAJQiuAACUILgCAFCC4AoAQAnGYQGrNXbX2VlZFxw3beoGZvpIzTgsjrMzqzmNFVcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKME4LGC1Lg6X9h/fHykuto3W1mV+0uId5z/boKunbmBmbOTV2KgsqOD0SG1FS6FWXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKEFwBQCgBOOwgPUxNkpowXo/vrOJKvzZFj6ya2Oxh5vb1tQNwBJtTt2AFVcAAIoQXAEAKEFwBQCgBMEVAIASBFcAAEowVQBYH/tTN8CqLHzywZnFHm5uK5yMASu3Bu8zK64AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUIJxWMD6MEqIea1yTM/YJK+dlXUBy9FGapsr62KQFVcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKOHQ47BaaxtJziV5uPf+itbaM5O8O8lTknwiyY/13g2zAea3P3UDlLXK4Y5bI7WxUVlQwemR2tiorBU5yorrTyW5/wmvfynJr/ben53k0SSvW2RjAADwRIcKrq2125L8cJJ3zF63JC9Nct/sS+5NctcS+gMAgCSHX3H9tSQ/l6//j7ynJHms9747e/1QklsX2xoAAHzdZYNra+0VSb7Ye//EPCdorb2htXautXbu4mMX5zkEAAAc6nH2O5P8SGvth5KcTfLkJG9LckNr7dRs1fW2JA9faufe+z1J7kmSp/7zp3psHQCAuVx2xbX3/ube+22992ckeW2SP+m9/2iSDyV51ezL7k7yvqV1CQDAiXclA0T+U5J3t9Z+Icknk7xzMS0BJ9bYmCEYs7nCcxn8yHG2yvfSHI4UXHvvH07y4dnvH0jygsW3BAAA/5ifnAUAQAmCKwAAJQiuAACUILgCAFCC4AoAQAlXMg4LYKGuGvu79Jx/ze59sT/3ZNHH4wjGroG2si6MbeN4OzN1A+OsuAIAUILgCgBACYIrAAAlCK4AAJQguAIAUIKpAsBKtT788e+NvjG840ipgnWfbrCMaQkL7/Hsiic67A9s311pF7B4Y1M4TBUAAIArJ7gCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCCcVjAao1NNDrGY4ZaG5s/M/3xShgZ07NzYWe4eM3IMcfGrG0PbF/xVC5YuLGRV2t+a7HiCgBACYIrAAAlCK4AAJQguAIAUILgCgBACYIrAAAlGIcFrNb+1A1Q1umR2oWR2t+P1DZHasZecVyNXfdrzoorAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJRgHBawWltTN0BVfWPO+VRju12c75BQ2pmpG5ifFVcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKME4LGC19qdugLJOT90AFDK2NGkcFgAALJfgCgBACYIrAAAlCK4AAJQguAIAUIKpAsBKte02dQtU5TsWHF7hyQFjrLgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCC4AoAQAmGiwCrtTdc6r2vro8RrRnZtZY2pm4ACtmcuoHlsOIKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJgisAACUYhwWsVN8eHnm1v7+/wk7WQ4XRW+vSYz+zHuPSoIQzUzewHFZcAQAoQXAFAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAE47CA1dqbuoH10vv6j3iq0COcWENLkKdX2sXKWHEFAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBKMwwJWa3fqBqiqbxrLBf/I5tQNrJYVVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAASjBVAFitnakboKw2dQOwhs5M3cBqWXEFAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBJWOw7rdJKnDtS+MrLf1wa29ytrB5jA3tQNUNYJG/sDh7I5dQOrZcUVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEpY7TisloORWJdyw8h+Tx7Y/tWRfcZquyM1YLm2pm6Aslb7HQvWRxup7a+si7VgxRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAASqgxXGQoXj9pZJ+x2sWR2qMjtT5SAw5nZHRL7+v/JmttbC4NS1XjOxYs3tit8UsD24fGjybJtSO1q0dqa3D7s+IKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJgisAACWczOEiY3/q9Z/GA6X1rZE3WYH3n5FdExob7wN8o52R2mMjtcdHamOjsq4Z2L7g960VVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAAShBcAQAo4WSOw9qeugE4wfanbuD4qzCyay6WWmD5xu7RXxmpfXVg+9g4rKERWiM9uA0AAFCC4AoAQAmCKwAAJQiuAACUILgCAFDCyZwqsDV1A3CCmerBvDanbgAYNDTMZOyeP1TbHd7FiisAACUIrgAAlCC4AgBQguAKAEAJgisAACUIrgAAlHCo4Npau6G1dl9r7bOttftba9/bWruptfZHrbW/mP3zxmU3uzBbI7+A5dod+QVjrhr5BZwIh327vy3JH/bevyPJdye5P8mbknyw9/6cJB+cvQYAgKW4bHBtrV2f5PuTvDNJeu/bvffHkrwyyb2zL7s3yV3LaREAAA634vrMJI8k+e3W2idba+9orV2b5Jbe+/nZ13whyS3LahIAAA4TXE8l+Z4kv9l7f36Sr+SbHgvovfcM/LCv1tobWmvnWmvnLv7txSvtFwCAE+owwfWhJA/13j82e31fDoLs37TWnp4ks39+8VI7997v6b3f0Xu/4+xTzi6iZwAATqDLBtfe+xeSfL619u2zTS9L8pkk709y92zb3Unet5QOAQAgB48BHMZ/TPKu1tqZJA8k+fEchN7faa29LsmDSV6znBbnNDZaZ39lXQDfzNgr5rU5dQPA1A4VXHvvn0pyxyVKL1toNwAAMMDYZgAAShBcAQAoQXAFAKAEwRUAgBIEVwAASjjsOKx6tqZuALiknakboKw2dQPA1Ky4AgBQguAKAEAJgisAACUIrgAAlCC4AgBQguAKAEAJxmEBq7U/dQOUtTl1A8DUrLgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFDC8Z0qsD11A8AlmfjBvDambgCYmhVXAABKEFwBAChBcAUAoATBFQCAEgRXAABKEFwBACih9jisnZHa/sq6AI7Ce5MxYyOvLLXAiec2AABACYIrAAAlCK4AAJQguAIAUILgCgBACYIrAAAl1B6HtT11A7BEZ0ZqfaS2O8c+q7Q1dQPLc/3jjw/Wrto/+hyw/auG1xa+/OQnH/l4JRiHBYxwGwAAoATBFQCAEgRXAABKEFwBAChBcAUAoATBFQCAEmqPwzrGY3Ug147Urh6p7Qxs/+rIPl8bqR19itO4RR9vxXZ3h+aNJf/iAx8YrD1rb+/I53pgY3g21Idf/erB2qlThW/tllOAEW4RAACUILgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFBC4ZkpSbanbgCuUBupbc55zNMD268f2efJI7WxUVljI7a+MrC9j+xTwKOPPjpYe9N11w3W/utNNx35XG/+u78brL1wpI+nPvWpRz7X2pj3ugdOBCuuAACUILgCAFCC4AoAQAmCKwAAJQiuAACUUGOqwM7A9v2VdgGLN/YOXOVfK8emG1wzZ+3MwPbiUwVOnx4a25DceOONg7XN7aOPQRk73lgfpVlOAUa4RQAAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACTXGYW1N3QAsyebUDSxR8bFXQ2644YbB2p133jlY2/jjPz7yue58yUuOvE95x/k9AVwxK64AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUIJxWDClM1M3sEQn8H173d///WDtW86fX+jxLjzpSUc+XgmWU4ARbhEAAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUEKNcVg7UzcAV6CN1DZX1sXq7U3dwOo9/1OfGqxtbh19PtjY8f73i1985OOVcHbqBoB1ZsUVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEpYn3FY2yO1/ZV1AYt3eqQ2NiqruotTN7B6O6fH/mNPf7wSNqZuAFhnVlwBAChBcAUAoATBFQCAEgRXAABKEFwBAChhfaYKbE3dACzJ5tQNTGRv6gaW40tf+tJg7a2f+9xg7bfa0UdIjB3v2771WwdrN99885HPtTbOTt0AsM6suAIAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACeszDmt76gZgSc5M3cBELk7dwHL03gdrz97dHax97ZprjnyuseON9VHa6akbANaZFVcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKGG147D67NelGIdFdW1g++ZKu1gfe1M3sBzXX3/9YO3bnvWswdojFy4c+VwvuO66wdr/G+mjNOOwgBFWXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKEFwBQCghNWPw9oZqUFlZ6ZuYM1sTd3Acpw5M/wf+q9f+MLh2qL7WPDx1sbZqRsA1pkVVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAAShBcAQAoYfXjsI7piBzI5tQNrJmh0XcwxnIKMMItAgCAEgRXAABKEFwBAChBcAUAoATBFQCAEkwVgEUxVeAb7U7dACV5HwEjrLgCAFCC4AoAQAmCKwAAJQiuAACUILgCAFCC4AoAQAmHGofVWvuZJK/PwUCrTyf58SRPT/LuJE9J8okkP9Z73x49UE+ycwXdwtTG/qp3emVd1HBx6gYoaWPqBoB1dtkV19barUl+Mskdvffn5eC28tokv5TkV3vvz07yaJLXLbNRAABOtsM+KnAqydWttVNJrklyPslLk9w3q9+b5K6FdwcAADOXDa6994eT/HKSz+UgsH45B48GPNZ7/4efjfNQklsvtX9r7Q2ttXOttXMXH/X/DgEAmM9hHhW4MckrkzwzybckuTbJyw97gt77Pb33O3rvd5y98ezcjQIAcLId5lGBH0zyV733R3rvO0nem+TOJDfMHh1IktuSPLykHgEA4FDB9XNJXtRau6a11pK8LMlnknwoyatmX3N3kvctp0UAADjEOKze+8daa/cl+bMku0k+meSeJB9I8u7W2i/Mtr3zsmfrs19Q1ZmpGyhkf+oGKOlQQxqBk+pQt4je+1uSvOWbNj+Q5AUL7wgAAC7BT84CAKAEwRUAgBIEVwAAShBcAQAoQXAFAKAEg0fgKDanbqCQr03dACWdnroBYJ1ZcQUAoATBFQCAEgRXAABKEFwBAChBcAUAoATBFQCAEozDgqMwDuvw9qZugJI2pm4AWGdWXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKKH13ld3stZWdzIAAErqvbdLbbfiCgBACYIrAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUILgCgBACaembgAAWJ0nz7nf4wvtAuZjxRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAASlibcVg33XTTYO2WW2655Pb7779/cJ8XvvCFg7Vz584N1m6//fbB2s7OziW3nz9/fnCfs2fPDta2trYGa3t7e4M1AJjX1XPuZxwW68CKKwAAJQiuAACUILgCAFCC4AoAQAmCKwAAJQiuAACUsDbjsN7ylrcM1m688cZLbv+93/u9wX1e8pKXDNa+67u+a7D24he/eLA2NA7rPe95z+A+r371qwdrv/7rvz5Y+/SnPz1YAwA4iay4AgBQguAKAEAJgisAACUIrgAAlCC4AgBQwtpMFdjb2xusffzjH7/k9jvvvHNwn3vuuWew9vrXv36w9vDDDw/Wrr766ktuv+WWWwb3ufnmmwdr11577WANAIBvZMUVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEpYm3FYGxsbg7WnPe1pl9z+4IMPDu7znd/5nYO1Rx55ZLA2NtrqqqsunfPH+nj7298+WHve8543WPvTP/3TwRoAwElkxRUAgBIEVwAAShBcAQAoQXAFAKAEwRUAgBIEVwAASmi999WdrLXBk33f933f4H5DY6Pe9a53De7zxje+cbD2G7/xG4O1H/iBHxisXbhw4ZLbP/vZzw7uc/fddw/W3vrWtx75XABwJTbn3G9roV3AuN57u9R2K64AAJQguAIAUILgCgBACYIrAAAlCK4AAJQguAIAUMLajMMCAIDEOCwAAIoTXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKOHU1A1wdG9+85uPvM9HPvKRwdpHP/rRkT1vHKn90JH7mNe1+SeDtZvynJX18eX8j8Ha4/nAyvoAgJPIiisAACUIrgAAlCC4AgBQguAKAEAJgisAACW03vvqTtba6k4GAEBJvfd2qe1WXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKEFwBQCgBMEVAIASBFcAAEoQXAEAKOHUis/3pSQPzn5/8+w1XIrrgzGuD8a4Phjj+lh//2yo0Hrvq2zk6ydu7Vzv/Y5JTs7ac30wxvXBGNcHY1wftXlUAACAEgRXAABKmDK43jPhuVl/rg/GuD4Y4/pgjOujsMmecQUAgKPwqAAAACVMElxbay9vrf3f1tpfttbeNEUPrI/W2u2ttQ+11j7TWvvz1tpPzbbf1Fr7o9baX8z+eePUvTKN1tpGa+2TrbX/OXv9zNbax2b3kPe01s5M3SPTaK3d0Fq7r7X22dba/a2173Xv4B+01n5m9n3l/7TW/ntr7az7R20rD66ttY0kb0/yr5M8N8m/ba09d9V9sFZ2k/xs7/25SV6U5Cdm18Sbknyw9/6cJB+cveZk+qkk9z/h9S8l+dXe+7OTPJrkdZN0xTp4W5I/7L1/R5LvzsF14t5BWmu3JvnJJHf03p+XZCPJa+P+UdoUK64vSPKXvfcHeu/bSd6d5JUT9MGa6L2f773/2ez3F3LwjefWHFwX986+7N4kd03SIJNqrd2W5IeTvGP2uiV5aZL7Zl/i2jihWmvXJ/n+JO9Mkt77du/9sbh38HWnklzdWjuV5Jok5+P+UdoUwfXWJJ9/wuuHZtsgrbVnJHl+ko8luaX3fn5W+kKSW6bqi0n9WpKfS7I/e/2UJI/13ndnr91DTq5nJnkkyW/PHiV5R2vt2rh3kKT3/nCSX07yuRwE1i8n+UTcP0rz4SzWRmvtSUl+N8lP994ff2KtH4y/MALjhGmtvSLJF3vvn5i6F9bSqSTfk+Q3e+/PT/KVfNNjAe4dJ9fs2eZX5uAvON+S5NokL5+0Ka7YFMH14SS3P+H1bbNtnGCttdM5CK3v6r2/d7b5b1prT5/Vn57ki1P1x2TuTPIjrbW/zsFjRS/NwTONN8z+11/iHnKSPZTkod77x2av78tBkHXvIEl+MMlf9d4f6b3vJHlvDu4p7h+FTRFcP57kObNP9Z3JwYPS75+gD9bE7JnFdya5v/f+K08ovT/J3bPf353kfavujWn13t/ce7+t9/6MHNwr/qT3/qNJPpTkVbMvc22cUL33LyT5fGvt22ebXpbkM3Hv4MDnkryotXbN7PvMP1wf7h+FTfIDCFprP5SD59Y2kvxW7/2/rLwJ1kZr7cVJPpLk0/n6c4w/n4PnXH8nyT9N8mCS1/Te/26SJplca+0lSd7Ye39Fa+1ZOViBvSnJJ5P8u9771oTtMZHW2r/MwQf3ziR5IMmP52BRxr2DtNb+c5J/k4PpNZ9M8vocPNPq/lGUn5wFAEAJPpwFAEAJgisAACUIrgAAlCC4AgBQguAKAEAJgisAACUIrgAAlCC4AgBQwv8HxBtxuaLrjIsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x864 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ver un estado segun ambiente\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(observation)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a266ca",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3407be0",
   "metadata": {},
   "source": [
    "**Simulacion de interaccion con teclado**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1dcb281",
   "metadata": {},
   "source": [
    "1) Simulador sencillo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1772814d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-15T22:47:08.516093Z",
     "start_time": "2022-11-15T22:46:57.606946Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Simulador de Carro con ingreso por teclado\n",
    "\n",
    "import pygame\n",
    "from gym.utils.play import play\n",
    "\n",
    "# Mapeo de teclados - modo discreto\n",
    "mapping = {(pygame.K_SPACE,): 0,(pygame.K_RIGHT,): 1, (pygame.K_LEFT,): 2,(pygame.K_UP,): 3,(pygame.K_DOWN,): 4}\n",
    "\n",
    "# Simular con interaccion por teclado de computadora\n",
    "play(gym.make(\"CarRacing-v2\",render_mode=\"rgb_array_list\",continuous=False,lap_complete_percent=1.00), keys_to_action=mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c766ba",
   "metadata": {},
   "source": [
    "2) Simulacion por teclado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f0dc2f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T04:48:00.353910Z",
     "start_time": "2022-11-16T04:47:49.630662Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Porcentaje a completar: 85.0 %\n",
      "Acciones del espacio: Discrete(5)\n",
      "-------------------------------------\n",
      "[INFO] Presione tecla para finalizar:  s\n",
      "[INICIO] Presione la tecla \"i\" para iniciar\n",
      "Se ha iniciado la simulacion\n",
      " *** Se presiono finalizar ***\n"
     ]
    }
   ],
   "source": [
    "# Simulador de Carro con ingreso por teclado\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "perc_complete = 0.85\n",
    "gym_env = \"CarRacing-v2\"\n",
    "\n",
    "env = gym.make(gym_env, render_mode=\"human\",\n",
    "               max_episode_steps=10000,\n",
    "               continuous=False,\n",
    "               lap_complete_percent=perc_complete)\n",
    "\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print('Porcentaje a completar:',np.round(100.*perc_complete,1),'%')\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "print('-------------------------------------')\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Tecla para finalizar\n",
    "tecla_finalizar = \"s\"\n",
    "print('[INFO] Presione tecla para finalizar: ',tecla_finalizar)\n",
    "\n",
    "# Informacion de teclados:\n",
    "## DERECHA: ir a la derecha (incluye girar)\n",
    "## IZQUIERDA: ir a la izquierda (incluye girar)\n",
    "## ARRIBA: avanzar aumentando velocidad\n",
    "## ABAJO: Reduce velocidad\n",
    "## TECLA SALIR definido arriba ver codigo lineas arriba\n",
    "\n",
    "# Parametro de finalizacion - en caso se equivoque mucho finalizar ya!!\n",
    "min_reward_to_finish = 12.5\n",
    "steps_batch = 300\n",
    "steps_to_finish = steps_batch\n",
    "reward_to_finish = 0\n",
    "finish_simulation = False\n",
    "\n",
    "#############################\n",
    "\n",
    "print('[INICIO] Presione la tecla \"i\" para iniciar')\n",
    "while(not keyboard.is_pressed(\"i\")):\n",
    "    pass\n",
    "\n",
    "print('Se ha iniciado la simulacion')\n",
    "observation, info = env.reset()\n",
    "\n",
    "#############################\n",
    "\n",
    "# Inicializar parametros\n",
    "time_start = time.time()\n",
    "reward_global = 0\n",
    "pasos_ciclo = 0\n",
    "num_ciclo = 1\n",
    "\n",
    "\n",
    "# Simulacion\n",
    "while True:\n",
    "    \n",
    "    # Accion por defecto en caso no se presione nada\n",
    "    accion = 0\n",
    "    \n",
    "    # En caso se presione alguna tecla en especifico\n",
    "    if keyboard.is_pressed(\"flecha derecha\"):\n",
    "        accion = 1\n",
    "    elif keyboard.is_pressed(\"flecha izquierda\"):\n",
    "        accion = 2\n",
    "    elif keyboard.is_pressed(\"flecha arriba\"):\n",
    "        accion = 3\n",
    "    elif keyboard.is_pressed(\"flecha abajo\"):\n",
    "        accion = 4\n",
    "    elif keyboard.is_pressed(tecla_finalizar):\n",
    "        print(' *** Se presiono finalizar ***')\n",
    "        break\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    # Leer estados del entorno\n",
    "    observation, reward, terminated, truncated, info = env.step(accion)\n",
    "    \n",
    "    reward_global += reward\n",
    "    pasos_ciclo += 1\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    #print('rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "        # Evaluar el reward ganado/perdido por cada intervalo. En caso no se evidencie mejora se finaliza\n",
    "    if(steps_to_finish < pasos_ciclo):\n",
    "        if(reward_global - reward_to_finish < min_reward_to_finish):\n",
    "            finish_simulation = True\n",
    "            \n",
    "        # Actualizar parametros\n",
    "        steps_to_finish += steps_batch\n",
    "        reward_to_finish = reward_global\n",
    "        \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated or finish_simulation:\n",
    "        \n",
    "        # Reset de entorno de simulacion\n",
    "        observation, info = env.reset()\n",
    "        \n",
    "        # tiempo de ciclo\n",
    "        duracion_ciclo = np.round(time.time() - time_start,1)\n",
    "        \n",
    "        # Informativo\n",
    "        print('# ciclo:',num_ciclo,'; completado:',terminated,'; truncado:',truncated,'; # pasos:',pasos_ciclo,'; reward:',np.round(reward_global,3),'; tiempo:',duracion_ciclo,'[sec] <> ',np.round(duracion_ciclo/60.0,2),'[min]')\n",
    "        \n",
    "        # Reiniciar/Actualizar variables\n",
    "        reward_global = 0\n",
    "        time_start = time.time()\n",
    "        pasos_ciclo = 0\n",
    "        num_ciclo += 1\n",
    "        \n",
    "        # Detener simulacion\n",
    "        steps_to_finish = steps_batch\n",
    "        reward_to_finish = 0\n",
    "        finish_simulation = False\n",
    "        \n",
    "        \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b460b66",
   "metadata": {},
   "source": [
    "3) Simulacion por teclado y generación de video para entrenamiento de Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3721a77e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-16T15:54:04.465583Z",
     "start_time": "2022-11-16T15:52:18.650013Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Escenario elegido de GymAI: CarRacing-v2\n",
      "Porcentaje a completar: 85.0 %\n",
      "Acciones del espacio: Discrete(5)\n",
      "-------------------------------------\n",
      "[INFO] Presione tecla para finalizar:  s\n",
      "[INICIO] Presione la tecla \"i\" para iniciar\n",
      "Se ha iniciado la simulacion\n",
      "# ciclo: 1 ; completado: False ; truncado: False ; # pasos: 1379 ; reward: 842.428 ; tiempo: 29.2 [sec] <>  0.49 [min]\n",
      "# ciclo: 2 ; completado: False ; truncado: False ; # pasos: 530 ; reward: 337.572 ; tiempo: 11.8 [sec] <>  0.2 [min]\n",
      "# ciclo: 3 ; completado: False ; truncado: True ; # pasos: 955 ; reward: 904.5 ; tiempo: 19.5 [sec] <>  0.32 [min]\n",
      "# ciclo: 4 ; completado: False ; truncado: False ; # pasos: 463 ; reward: 323.953 ; tiempo: 10.5 [sec] <>  0.18 [min]\n",
      "# ciclo: 5 ; completado: False ; truncado: False ; # pasos: 578 ; reward: 508.302 ; tiempo: 12.8 [sec] <>  0.21 [min]\n",
      "# ciclo: 6 ; completado: False ; truncado: False ; # pasos: 870 ; reward: 735.785 ; tiempo: 18.8 [sec] <>  0.31 [min]\n",
      " *** Se presiono finalizar ***\n"
     ]
    }
   ],
   "source": [
    "# [Generar videos] Simulador de Carro con ingreso por teclado & grabar video\n",
    "\n",
    "## NOTA: En este simulador de carro se indica el % de recorrido para considerar finalizado \"lap_complete_percent\"\n",
    "## NOTA: El modo \"continuos\" es diferente al discreto\n",
    "\n",
    "\n",
    "perc_complete = 0.85\n",
    "gym_env = \"CarRacing-v2\"\n",
    "\n",
    "env = gym.make(gym_env, render_mode=\"human\",\n",
    "               max_episode_steps=10000,\n",
    "               continuous=False,\n",
    "               lap_complete_percent=perc_complete)\n",
    "\n",
    "print('Escenario elegido de GymAI:',gym_env)\n",
    "print('Porcentaje a completar:',np.round(100.*perc_complete,1),'%')\n",
    "print(\"Acciones del espacio:\",env.action_space)\n",
    "print('-------------------------------------')\n",
    "\n",
    "# reset para que no cambie colores de fondo\n",
    "env.reset(options={\"randomize\": False})\n",
    "\n",
    "#########################################\n",
    "\n",
    "# Seteo de semilla inicio\n",
    "env.action_space.seed(42)\n",
    "observation, info = env.reset(seed=42)\n",
    "\n",
    "# Tecla para finalizar\n",
    "tecla_finalizar = \"s\"\n",
    "print('[INFO] Presione tecla para finalizar: ',tecla_finalizar)\n",
    "\n",
    "# Tecla para finalizar ciclo actual\n",
    "tecla_finaliza_ciclo = \"C\"\n",
    "\n",
    "# Informacion de teclados:\n",
    "## DERECHA: ir a la derecha (incluye girar)\n",
    "## IZQUIERDA: ir a la izquierda (incluye girar)\n",
    "## ARRIBA: avanzar aumentando velocidad\n",
    "## ABAJO: Reduce velocidad\n",
    "## TECLA SALIR: \"S\"      (Definido lineas arriba)\n",
    "## TECLA Finaliza ciclo actual: \"C\"   (Definido lineas arriba)\n",
    "\n",
    "# Parametro de finalizacion - en caso se equivoque mucho finalizar ya!!\n",
    "min_reward_to_finish = 12.5\n",
    "steps_batch = 300\n",
    "steps_to_finish = steps_batch\n",
    "reward_to_finish = 0\n",
    "finish_simulation = False\n",
    "\n",
    "#############################\n",
    "\n",
    "print('[INICIO] Presione la tecla \"i\" para iniciar')\n",
    "while(not keyboard.is_pressed(\"i\")):\n",
    "    pass\n",
    "\n",
    "print('Se ha iniciado la simulacion')\n",
    "observation, info = env.reset()\n",
    "\n",
    "#############################\n",
    "\n",
    "# Inicializar parametros\n",
    "time_start = time.time()\n",
    "reward_global = 0\n",
    "pasos_ciclo = 0\n",
    "num_ciclo = 1\n",
    "\n",
    "################################\n",
    "# Variable para guardar video\n",
    "num_simulacion = 1\n",
    "nombre_video = \"simula_\"+ str(num_simulacion) + \"_\" + str(num_ciclo) +\".mp4\"\n",
    "frame_size = env.observation_space.shape[:2]\n",
    "fps = 60\n",
    "\n",
    "# Inicio grabacion video\n",
    "result_video = cv2.VideoWriter(nombre_video, cv2.VideoWriter_fourcc(*'MP4V'),fps, frame_size)\n",
    "#################################\n",
    "\n",
    "# Simulacion\n",
    "while True:\n",
    "    \n",
    "    # Accion por defecto en caso no se presione nada\n",
    "    accion = 0\n",
    "    \n",
    "    # En caso se presione alguna tecla en especifico\n",
    "    if keyboard.is_pressed(\"flecha derecha\"):\n",
    "        accion = 1\n",
    "    elif keyboard.is_pressed(\"flecha izquierda\"):\n",
    "        accion = 2\n",
    "    elif keyboard.is_pressed(\"flecha arriba\"):\n",
    "        accion = 3\n",
    "    elif keyboard.is_pressed(\"flecha abajo\"):\n",
    "        accion = 4\n",
    "    elif keyboard.is_pressed(tecla_finaliza_ciclo):\n",
    "        finish_simulation = True\n",
    "        time.sleep(1) # esperar 1 segundo\n",
    "    elif keyboard.is_pressed(tecla_finalizar):\n",
    "        print(' *** Se presiono finalizar ***')\n",
    "        try:\n",
    "            # finaliza video\n",
    "            result_video.release()\n",
    "        except:\n",
    "            pass\n",
    "        # finalizar bucle while\n",
    "        break\n",
    "    \n",
    "    ######################################################\n",
    "    \n",
    "    # Leer estados del entorno\n",
    "    observation, reward, terminated, truncated, info = env.step(accion)\n",
    "    \n",
    "    reward_global += reward\n",
    "    pasos_ciclo += 1\n",
    "    \n",
    "    # Guadar imagen a video\n",
    "    result_video.write(observation[:,:,::-1])\n",
    "    \n",
    "    ## Observado - Interaccion\n",
    "    #print('obs:',observation,';rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    #print('rew:',reward,';term:',terminated,';trun:',truncated,';info:',info)\n",
    "    \n",
    "        # Evaluar el reward ganado/perdido por cada intervalo. En caso no se evidencie mejora se finaliza\n",
    "    if(steps_to_finish < pasos_ciclo):\n",
    "        if(reward_global - reward_to_finish < min_reward_to_finish):\n",
    "            finish_simulation = True\n",
    "            \n",
    "        # Actualizar parametros\n",
    "        steps_to_finish += steps_batch\n",
    "        reward_to_finish = reward_global\n",
    "        \n",
    "    # En caso haya logrado alcanzar el objetivo se indica\n",
    "    if terminated or truncated or finish_simulation:\n",
    "        \n",
    "        # Reset de entorno de simulacion\n",
    "        observation, info = env.reset()\n",
    "        \n",
    "        # tiempo de ciclo\n",
    "        duracion_ciclo = np.round(time.time() - time_start,1)\n",
    "        \n",
    "        # Informativo\n",
    "        print('# ciclo:',num_ciclo,'; completado:',terminated,'; truncado:',truncated,'; # pasos:',pasos_ciclo,'; reward:',np.round(reward_global,3),'; tiempo:',duracion_ciclo,'[sec] <> ',np.round(duracion_ciclo/60.0,2),'[min]')\n",
    "        \n",
    "        # Finaliza video\n",
    "        result_video.release()\n",
    "\n",
    "        # Reiniciar/Actualizar variables\n",
    "        reward_global = 0\n",
    "        time_start = time.time()\n",
    "        pasos_ciclo = 0\n",
    "        num_ciclo += 1\n",
    "        \n",
    "        # Detener simulacion\n",
    "        steps_to_finish = steps_batch\n",
    "        reward_to_finish = 0\n",
    "        finish_simulation = False\n",
    "        \n",
    "        # Inicializar video - empieza a grabar nuevo archivo\n",
    "        nombre_video = \"simula_\"+ str(num_simulacion) + \"_\" + str(num_ciclo) +\".mp4\"\n",
    "        result_video = cv2.VideoWriter(nombre_video, cv2.VideoWriter_fourcc(*'MP4V'),fps, frame_size)\n",
    "        \n",
    "# Cerrar entorno\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de37c927",
   "metadata": {},
   "source": [
    "## Q-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d564aa65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:13:38.306791Z",
     "start_time": "2022-11-28T03:13:33.124738Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Tabla inicial:\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "\n",
      "===========================================\n",
      "Q-Tabla final:\n",
      "[[1.0097379  1.121931   1.121931   1.0097379 ]\n",
      " [1.0097379  0.9        1.24659    1.121931  ]\n",
      " [1.121931   1.3851     1.121931   1.24659   ]\n",
      " [1.24659    0.9000001  1.12183692 1.11811728]\n",
      " [1.12191938 1.24659    0.9        1.00973667]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.9        1.539      0.9        1.24659   ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.22717071 0.90000001 1.3851     1.12192259]\n",
      " [1.24570186 1.53816638 1.539      0.9       ]\n",
      " [1.3851     1.71       0.9        1.3851    ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.903125   1.53320709 1.71       1.3813835 ]\n",
      " [1.539      1.71       1.9        1.539     ]\n",
      " [1.         1.         1.         1.        ]]\n",
      "Cantidad exito: 4508  de  5000 ; Ratio de exito= 90.16 %\n"
     ]
    }
   ],
   "source": [
    "# Caso 1 - tabla 4x4\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "environment = gym.make(\"FrozenLake-v1\", is_slippery=False,map_name=\"4x4\")\n",
    "environment.reset()\n",
    "environment.render()\n",
    "\n",
    "nb_states = environment.observation_space.n\n",
    "nb_actions = environment.action_space.n \n",
    "qtable = np.zeros((nb_states, nb_actions))\n",
    "\n",
    "# Artificio de agregar un valor diferente de cero inicial\n",
    "qtable = qtable + 1\n",
    "\n",
    "# Hiperparametros\n",
    "episodes = 5000        # numero episodios\n",
    "alpha = 0.5            # Learning rate\n",
    "gamma = 0.9            # Discount factor\n",
    "epsilon = 0.90          # Amount of randomness in the action selection\n",
    "epsilon_decay = 0.001  # Fixed amount to decrease\n",
    "max_ii = 50            # limite de pasos por episodio\n",
    "\n",
    "\n",
    "print('Q-Tabla inicial:')\n",
    "print(qtable)\n",
    "\n",
    "# Llevar conteo de casos de exito\n",
    "cantidad_exitos = 0\n",
    "\n",
    "# Entrenamiento\n",
    "for ii in range(episodes):\n",
    "    \n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # entrenar y actualizar matriz Q\n",
    "    while not done:\n",
    "        \n",
    "        # valor aleatorio entre 0 y 1\n",
    "        rnd = np.random.random()\n",
    "\n",
    "        # si se cumple rnd < epsilon tomar una accion aleatoria\n",
    "        if rnd < epsilon:\n",
    "            action = environment.action_space.sample()\n",
    "            \n",
    "        # si no es aleatorio, seleccionar la opcion con Q mas alto\n",
    "        else:\n",
    "            # Opcion 1\n",
    "            #action = np.argmax(qtable[state])\n",
    "            \n",
    "            # Opcion 2\n",
    "            vector = qtable[state]\n",
    "            action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "             \n",
    "        # aplicar accion\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "\n",
    "        # Actualiza el valor de Q(s,a) segun accion y estado\n",
    "        qtable[state, action] = qtable[state, action] + \\\n",
    "                                alpha * (reward + gamma * np.max(qtable[new_state]) - qtable[state, action])\n",
    "        \n",
    "        # actualiza estado actual\n",
    "        state = new_state\n",
    "\n",
    "        # Se ganó la busqueda del objetivo principal\n",
    "        if reward:\n",
    "            cantidad_exitos += 1\n",
    "            #print('Exito en episodio:',ii,'; pasos:',pasos_ii,'; estado:',state,'; reward:',reward)\n",
    "            \n",
    "        pasos_ii +=1\n",
    "        if(pasos_ii > max_ii):\n",
    "            break\n",
    "\n",
    "    # Actualizar epsilon\n",
    "    epsilon = max(epsilon - epsilon_decay, 0)\n",
    "\n",
    "print()\n",
    "print('===========================================')\n",
    "print('Q-Tabla final:')\n",
    "print(qtable)\n",
    "\n",
    "print (\"Cantidad exito:\",cantidad_exitos,\" de \",episodes,\"; Ratio de exito=\",np.round(100.*(cantidad_exitos/episodes),3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e070c9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T03:13:46.633895Z",
     "start_time": "2022-11-28T03:13:46.588637Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 ; action: 2 ; state: 1 ; reward: 0.0\n",
      "Episode: 0 ; action: 2 ; state: 2 ; reward: 0.0\n",
      "Episode: 0 ; action: 1 ; state: 6 ; reward: 0.0\n",
      "Episode: 0 ; action: 1 ; state: 10 ; reward: 0.0\n",
      "Episode: 0 ; action: 1 ; state: 14 ; reward: 0.0\n",
      "Episode: 0 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 1 ; action: 2 ; state: 1 ; reward: 0.0\n",
      "Episode: 1 ; action: 2 ; state: 2 ; reward: 0.0\n",
      "Episode: 1 ; action: 1 ; state: 6 ; reward: 0.0\n",
      "Episode: 1 ; action: 1 ; state: 10 ; reward: 0.0\n",
      "Episode: 1 ; action: 1 ; state: 14 ; reward: 0.0\n",
      "Episode: 1 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 2 ; action: 2 ; state: 1 ; reward: 0.0\n",
      "Episode: 2 ; action: 2 ; state: 2 ; reward: 0.0\n",
      "Episode: 2 ; action: 1 ; state: 6 ; reward: 0.0\n",
      "Episode: 2 ; action: 1 ; state: 10 ; reward: 0.0\n",
      "Episode: 2 ; action: 1 ; state: 14 ; reward: 0.0\n",
      "Episode: 2 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 3 ; action: 2 ; state: 1 ; reward: 0.0\n",
      "Episode: 3 ; action: 2 ; state: 2 ; reward: 0.0\n",
      "Episode: 3 ; action: 1 ; state: 6 ; reward: 0.0\n",
      "Episode: 3 ; action: 1 ; state: 10 ; reward: 0.0\n",
      "Episode: 3 ; action: 1 ; state: 14 ; reward: 0.0\n",
      "Episode: 3 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Episode: 4 ; action: 2 ; state: 1 ; reward: 0.0\n",
      "Episode: 4 ; action: 2 ; state: 2 ; reward: 0.0\n",
      "Episode: 4 ; action: 1 ; state: 6 ; reward: 0.0\n",
      "Episode: 4 ; action: 1 ; state: 10 ; reward: 0.0\n",
      "Episode: 4 ; action: 1 ; state: 14 ; reward: 0.0\n",
      "Episode: 4 ; action: 2 ; state: 15 ; reward: 1.0\n",
      "Ratio de exito= 100.0 %\n"
     ]
    }
   ],
   "source": [
    "# Aplicar a \"Q\" entrenado\n",
    "\n",
    "# Cantidad de simulaciones\n",
    "episodes = 5\n",
    "\n",
    "# Registro de simulaciones exitosas\n",
    "nb_success = 0\n",
    "\n",
    " # limite de pasos por episodio\n",
    "max_ii = 50\n",
    "\n",
    "# Evaluacion\n",
    "for ii in range(episodes):\n",
    "\n",
    "    # Inicializar entorno\n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # Hasta que finalice o se atore\n",
    "    while not done:\n",
    "        \n",
    "        # Opcion 1\n",
    "        #action = np.argmax(qtable[state])\n",
    "\n",
    "        # Opcion 2\n",
    "        vector = qtable[state]\n",
    "        action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "\n",
    "        # Aplicar accion y ver nuevos estados\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        #print('Estado:',new_state,'; Recompensa:',reward,'; Finalizacion:',done)\n",
    "        \n",
    "        # Actualizar estado\n",
    "        state = new_state\n",
    "        \n",
    "        # information\n",
    "        print('Episode:',ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "        \n",
    "        # Si se da recomensa, se ganó el juego\n",
    "        nb_success += reward\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        if(pasos_ii > max_ii):\n",
    "            break\n",
    "\n",
    "print (\"Ratio de exito=\",np.round(100.*(nb_success/episodes),1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f215acd3",
   "metadata": {},
   "source": [
    "Para el caso de un tablero 4x4 se ve que se logró aprender la matriz Q para la deteminación de la \"acción\" segun el estado. Por lo que el objeto es capaz de navegar hacia la busqueda de la mayor recompensa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77374a3e",
   "metadata": {},
   "source": [
    "Caso 2 - tabla 8x8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "9ba93cac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T02:47:00.873373Z",
     "start_time": "2022-11-28T02:46:07.474025Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-Tabla inicial:\n",
      "[[1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]\n",
      " [1. 1. 1. 1.]]\n",
      "Exito en episodio: 237 ; pasos: 33 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 426 ; pasos: 41 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 665 ; pasos: 24 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 795 ; pasos: 36 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 973 ; pasos: 33 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 1202 ; pasos: 23 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 1420 ; pasos: 52 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 1643 ; pasos: 18 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 1846 ; pasos: 56 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 2044 ; pasos: 38 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 2241 ; pasos: 40 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 2461 ; pasos: 70 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 2684 ; pasos: 19 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 2891 ; pasos: 43 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 3133 ; pasos: 31 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 3336 ; pasos: 82 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 3538 ; pasos: 42 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 3746 ; pasos: 64 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 3947 ; pasos: 74 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 4165 ; pasos: 36 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 4399 ; pasos: 26 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 4608 ; pasos: 36 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 4800 ; pasos: 34 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 4996 ; pasos: 35 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 5219 ; pasos: 55 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 5416 ; pasos: 138 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 5653 ; pasos: 23 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 5865 ; pasos: 75 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 6084 ; pasos: 39 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 6270 ; pasos: 50 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 6492 ; pasos: 60 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 6509 ; pasos: 32 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 6688 ; pasos: 81 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 6906 ; pasos: 68 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 7133 ; pasos: 46 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 7351 ; pasos: 33 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 7558 ; pasos: 63 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 7749 ; pasos: 48 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 7954 ; pasos: 46 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 8168 ; pasos: 76 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 8404 ; pasos: 14 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 8606 ; pasos: 47 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 8845 ; pasos: 55 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 9017 ; pasos: 48 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 9230 ; pasos: 94 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 9442 ; pasos: 48 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 9667 ; pasos: 85 ; estado: 63 ; reward: 1.0\n",
      "Exito en episodio: 9870 ; pasos: 59 ; estado: 63 ; reward: 1.0\n",
      "\n",
      "===========================================\n",
      "Q-Tabla final:\n",
      "[[0.99400902 0.99400873 0.99400872 0.99400902]\n",
      " [0.99628594 0.99628609 0.9962858  0.99628591]\n",
      " [0.99769785 0.99769821 0.99769773 0.99769815]\n",
      " [0.99862039 0.9986201  0.9986202  0.99862045]\n",
      " [0.99912917 0.99912885 0.99912918 0.99912888]\n",
      " [0.99940512 0.99940495 0.99940498 0.99940518]\n",
      " [0.99954649 0.99954646 0.99954686 0.9995466 ]\n",
      " [0.99960635 0.9996068  0.99960658 0.99960658]\n",
      " [0.99627794 0.99627781 0.99627799 0.99627756]\n",
      " [0.9972297  0.9972297  0.99722994 0.99722992]\n",
      " [0.99821837 0.99821868 0.99821834 0.99821825]\n",
      " [0.99904647 0.99904621 0.99904637 0.99904659]\n",
      " [0.99936577 0.99936604 0.99936576 0.99936577]\n",
      " [0.99954034 0.99954008 0.99954049 0.99954051]\n",
      " [0.99962876 0.99962854 0.9996287  0.99962878]\n",
      " [0.99966594 0.99966636 0.99966606 0.99966637]\n",
      " [0.99767321 0.99767309 0.99767341 0.99767294]\n",
      " [0.99817248 0.99817224 0.9981724  0.99817231]\n",
      " [0.99892292 0.99892272 0.99892277 0.99892289]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.99975112 0.99975083 0.99975106 0.99975112]\n",
      " [0.999763   0.99976306 0.99976303 0.99976303]\n",
      " [0.99976203 0.99976183 0.99976203 0.99976223]\n",
      " [0.99976352 0.99976375 0.99976353 0.99976331]\n",
      " [0.99859898 0.99859929 0.99859882 0.99859919]\n",
      " [0.99888509 0.99888474 0.99888481 0.99888508]\n",
      " [0.99932341 0.99932362 0.99932331 0.99932365]\n",
      " [0.99979962 0.9997994  0.99979917 0.9997994 ]\n",
      " [0.99987742 0.9998776  0.99987715 0.99987736]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.99989311 0.99989306 0.99989347 0.99989337]\n",
      " [0.99986205 0.9998621  0.99986251 0.99986238]\n",
      " [0.99925278 0.99925255 0.99925273 0.99925265]\n",
      " [0.9994561  0.99945598 0.99945638 0.99945621]\n",
      " [0.99969436 0.99969394 0.99969394 0.99969397]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.99995952 0.99996001 0.99996001 0.99995997]\n",
      " [0.999975   0.999975   0.99997499 0.99997451]\n",
      " [0.99994951 0.99994903 0.99994949 0.99994947]\n",
      " [0.99992952 0.99992903 0.9999295  0.99992946]\n",
      " [0.99970904 0.99970901 0.99970885 0.99970928]\n",
      " [1.         1.         1.         1.        ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.999996   0.9999965  0.9999965  0.999996  ]\n",
      " [0.9999865  0.9999865  0.9999865  0.999987  ]\n",
      " [0.99999    0.9999895  0.9999895  0.99999   ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.99997601 0.9999761  0.9999765  0.99997649]\n",
      " [0.99987801 0.99987806 0.99987765 0.99987781]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.999997   0.999997   0.999997   0.999997  ]\n",
      " [0.9999985  0.9999985  0.999998   0.9999985 ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.999997   0.9999975  0.999997   0.9999975 ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.9999995  1.0004369  0.9999995  0.9999995 ]\n",
      " [0.999925   0.999925   0.99992454 0.99992497]\n",
      " [0.99997149 0.9999715  0.99997151 0.99997101]\n",
      " [0.9999895  0.9999895  0.9999895  0.9999895 ]\n",
      " [1.         1.         1.         1.        ]\n",
      " [0.9999995  0.9999995  1.         0.9999995 ]\n",
      " [0.999999   0.9999995  0.999999   0.9999995 ]\n",
      " [1.         1.         1.000019   1.        ]\n",
      " [1.         1.         1.         1.        ]]\n",
      "Cantidad exito: 48  de  10000 ; Ratio de exito= 0.48 %\n"
     ]
    }
   ],
   "source": [
    "# Caso 2 - tabla 8x8\n",
    "\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "environment = gym.make(\"FrozenLake-v1\", is_slippery=False,map_name=\"8x8\")\n",
    "environment.reset()\n",
    "environment.render()\n",
    "\n",
    "nb_states = environment.observation_space.n\n",
    "nb_actions = environment.action_space.n \n",
    "qtable = np.zeros((nb_states, nb_actions))\n",
    "\n",
    "# Artificio de agregar un valor diferente de cero inicial\n",
    "qtable = qtable + 1\n",
    "\n",
    "# Hiperparametros\n",
    "episodes = 10000        # numero episodios\n",
    "alpha = 1e-5            # Learning rate\n",
    "gamma = 0.95           # Discount factor\n",
    "epsilon = 0.7          # Amount of randomness in the action selection\n",
    "epsilon_decay = 0.001   # Fixed amount to decrease\n",
    "max_ii = 200            # limite de pasos por episodio\n",
    "\n",
    "print('Q-Tabla inicial:')\n",
    "print(qtable)\n",
    "\n",
    "# Llevar conteo de casos de exito\n",
    "cantidad_exitos = 0\n",
    "\n",
    "# guardar casos de exito\n",
    "camino_exitoso = []\n",
    "\n",
    "# Entrenamiento\n",
    "for ii in range(episodes):\n",
    "    \n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # camino seguido en episodio \n",
    "    camino_episodio_actual = []\n",
    "    \n",
    "    # entrenar y actualizar matriz Q\n",
    "    while not done:\n",
    "        \n",
    "        # valor aleatorio entre 0 y 1\n",
    "        rnd = np.random.random()\n",
    "\n",
    "        # si se cumple rnd < epsilon tomar una accion aleatoria\n",
    "        if rnd < epsilon:\n",
    "            action = environment.action_space.sample()\n",
    "            \n",
    "        # si no es aleatorio, seleccionar la opcion con Q mas alto\n",
    "        else:\n",
    "            # Opcion 1\n",
    "            #action = np.argmax(qtable[state])\n",
    "            \n",
    "            # Opcion 2\n",
    "            vector = qtable[state]\n",
    "            action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "             \n",
    "        # aplicar accion\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        # guardar camino\n",
    "        camino_episodio_actual.append((state,action,new_state))\n",
    "        \n",
    "        # Actualiza el valor de Q(s,a) segun accion y estado\n",
    "        qtable[state, action] = qtable[state, action] + \\\n",
    "                                alpha * (reward + gamma * np.max(qtable[new_state]) - qtable[state, action])\n",
    "        \n",
    "        # actualiza estado actual\n",
    "        state = new_state\n",
    "        \n",
    "        # Se ganó la busqueda del objetivo principal\n",
    "        if reward:\n",
    "            cantidad_exitos += 1\n",
    "            camino_exitoso.append(camino_episodio_actual) # agregar camino de episodio actual a caso de exito\n",
    "            print('Exito en episodio:',ii,'; pasos:',pasos_ii,'; estado:',state,'; reward:',reward)\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        if(pasos_ii > max_ii):\n",
    "            break\n",
    "\n",
    "    # Actualizar epsilon\n",
    "    epsilon = max(epsilon - epsilon_decay, 0)\n",
    "\n",
    "print()\n",
    "print('===========================================')\n",
    "print('Q-Tabla final:')\n",
    "print(qtable)\n",
    "\n",
    "print (\"Cantidad exito:\",cantidad_exitos,\" de \",episodes,\"; Ratio de exito=\",np.round(100.*(cantidad_exitos/episodes),3),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "a4beff56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T02:50:48.408239Z",
     "start_time": "2022-11-28T02:50:48.390717Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de caminos exitosos\n",
    "len(camino_exitoso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "4c82ae62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T02:50:15.273702Z",
     "start_time": "2022-11-28T02:50:15.246247Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2, 1),\n",
       " (1, 2, 2),\n",
       " (2, 1, 10),\n",
       " (10, 0, 9),\n",
       " (9, 1, 17),\n",
       " (17, 3, 9),\n",
       " (9, 3, 1),\n",
       " (1, 3, 1),\n",
       " (1, 0, 0),\n",
       " (0, 3, 0),\n",
       " (0, 0, 0),\n",
       " (0, 1, 8),\n",
       " (8, 3, 0),\n",
       " (0, 2, 1),\n",
       " (1, 1, 9),\n",
       " (9, 0, 8),\n",
       " (8, 0, 8),\n",
       " (8, 2, 9),\n",
       " (9, 2, 10),\n",
       " (10, 2, 11),\n",
       " (11, 2, 12),\n",
       " (12, 3, 4),\n",
       " (4, 2, 5),\n",
       " (5, 2, 6),\n",
       " (6, 3, 6),\n",
       " (6, 0, 5),\n",
       " (5, 1, 13),\n",
       " (13, 1, 21),\n",
       " (21, 2, 22),\n",
       " (22, 1, 30),\n",
       " (30, 3, 22),\n",
       " (22, 3, 14),\n",
       " (14, 0, 13),\n",
       " (13, 3, 5),\n",
       " (5, 3, 5),\n",
       " (5, 0, 4),\n",
       " (4, 3, 4),\n",
       " (4, 1, 12),\n",
       " (12, 2, 13),\n",
       " (13, 2, 14),\n",
       " (14, 2, 15),\n",
       " (15, 2, 15),\n",
       " (15, 0, 14),\n",
       " (14, 1, 22),\n",
       " (22, 2, 23),\n",
       " (23, 3, 15),\n",
       " (15, 3, 7),\n",
       " (7, 2, 7),\n",
       " (7, 3, 7),\n",
       " (7, 0, 6),\n",
       " (6, 1, 14),\n",
       " (14, 3, 6),\n",
       " (6, 2, 7),\n",
       " (7, 1, 15),\n",
       " (15, 1, 23),\n",
       " (23, 1, 31),\n",
       " (31, 1, 39),\n",
       " (39, 1, 47),\n",
       " (47, 1, 55),\n",
       " (55, 1, 63)]"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ver cada camino seguido\n",
    "\n",
    "# cada tupla se lee: (state_actual, action, new_state)\n",
    "i = -1\n",
    "camino_exitoso[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840e97f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-11-28T02:51:27.029879Z",
     "start_time": "2022-11-28T02:51:26.887966Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Aplicar a \"Q\" entrenado\n",
    "\n",
    "# Cantidad de simulaciones\n",
    "episodes = 10\n",
    "\n",
    "# Registro de simulaciones exitosas\n",
    "nb_success = 0\n",
    "\n",
    " # limite de pasos por episodio\n",
    "max_ii = 50\n",
    "\n",
    "# Evaluacion\n",
    "for ii in range(episodes):\n",
    "\n",
    "    # Inicializar entorno\n",
    "    state = environment.reset()\n",
    "    state = state[0]\n",
    "    done = False\n",
    "    \n",
    "    # Contador de while ejecutado en episodio actual\n",
    "    pasos_ii = 0\n",
    "    \n",
    "    # Hasta que finalice o se atore\n",
    "    while not done:\n",
    "        \n",
    "        # Opcion 1\n",
    "        action = np.argmax(qtable[state])\n",
    "\n",
    "        # Opcion 2\n",
    "        vector = qtable[state]\n",
    "        action = np.random.choice(np.where(vector == np.max(vector))[0],1)[0]\n",
    "\n",
    "        # Aplicar accion y ver nuevos estados\n",
    "        new_state, reward, done, info, _ = environment.step(action)\n",
    "        \n",
    "        #print('Estado:',new_state,'; Recompensa:',reward,'; Finalizacion:',done)\n",
    "        \n",
    "        # Actualizar estado\n",
    "        state = new_state\n",
    "        \n",
    "        # information\n",
    "        print('Episode:',ii,'; action:',action,'; state:',state,'; reward:',reward)\n",
    "        \n",
    "        # Si se da recomensa, se ganó el juego\n",
    "        nb_success += reward\n",
    "        \n",
    "        pasos_ii +=1\n",
    "        if(pasos_ii > max_ii):\n",
    "            break\n",
    "\n",
    "print (\"Ratio de exito=\",np.round(100.*(nb_success/episodes),1),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90bc4d3",
   "metadata": {},
   "source": [
    "En este caso se ve que para un tablero de 8x8, el algoritmo no logró aprender adecuadamente, viendose reflejado en la proporción de casos de exito. Al evaluarse dichos casos de exito se evidencia que en muchos casos fue cuestión de casos fortuitos aleatorios más no un aprendizaje verdadero del camino adecuado."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
